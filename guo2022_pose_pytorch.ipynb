{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# from keras.layers import BatchNormalization, Dense, Input, Conv1D, Add, ELU, Flatten, MaxPooling1D\n",
    "# from keras.layers import GlobalAveragePooling1D, Softmax, Concatenate, Reshape, Multiply, ReLU\n",
    "# from keras.optimizers import SGD\n",
    "# from keras import activations\n",
    "# from keras import Model\n",
    "# from keras.initializers import HeNormal\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_symbolic import Input, SymbolicModel, useful_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# dataset\n",
    "class DAICDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations_file,\n",
    "        sample_dir,\n",
    "        feature_type,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "    ):\n",
    "        self.depression_labels = pd.read_csv(annotations_file)\n",
    "        self.sample_dir = sample_dir\n",
    "        self.feature_type = feature_type\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.depression_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        participant_id = self.depression_labels.iloc[idx, 0]\n",
    "        participant_path = os.path.join(\n",
    "            self.sample_dir,\n",
    "            participant_id\n",
    "            + \"/\"\n",
    "            + participant_id\n",
    "            + \"_CLNF_\"\n",
    "            + self.feature_type\n",
    "            + \".txt\",\n",
    "        )\n",
    "        data = pd.read_csv(participant_path, sep=\",\")  # read_image(img_path)\n",
    "        data.columns = data.columns.str.replace(\" \", \"\")\n",
    "        data.drop(columns=[\"frame\", \"timestamp\", \"confidence\", \"success\"], inplace=True)\n",
    "        label = self.depression_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data.loc[1000:5999], label\n",
    "\n",
    "\n",
    "label_path = Path(\"original_daic/labels\")\n",
    "pose_train = DAICDataset(\n",
    "    annotations_file = label_path / \"train_split_Depression_AVEC2017.csv\",\n",
    "    sample_dir = \"original_daic/train\",\n",
    "    feature_type = \"pose\",\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    ")\n",
    "pose_dev = DAICDataset(\n",
    "    annotations_file = label_path / \"dev_split_Depression_AVEC2017.csv\",\n",
    "    sample_dir = \"original_daic/dev\",\n",
    "    feature_type = \"pose\",\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    ")\n",
    "pose_test = DAICDataset(\n",
    "    annotations_file = label_path / \"full_test_split.csv\",\n",
    "    sample_dir = \"original_daic/test\",\n",
    "    feature_type = \"pose\",\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "BATCH_SIZE = 1\n",
    "train_dataloader = DataLoader(pose_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = DataLoader(pose_dev, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(pose_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pose = Input(shape=[6, 5000])\n",
    "tdcn_dim_pose = [input_pose[0],128,64,256,128,64] # used in Guo's paper\n",
    "# tdcn_dim_pose = [input_pose[0],128,128,128,128,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diluted_conv_block(inputs, input_dim, feature_dim):\n",
    "    # with K.name_scope(block_name)\n",
    "    l1_p1 = nn.Conv1d(input_dim, feature_dim, kernel_size=3, padding=\"same\", dilation=1, bias=True)(inputs)\n",
    "    l1_p2 = nn.Conv1d(input_dim, feature_dim, kernel_size=3, padding=\"same\", dilation=1, bias=True)(inputs)\n",
    "    # l1_add = Add()([l1_p1, l1_p2])\n",
    "    l1_ELU = nn.ELU()(l1_p1 + l1_p2)\n",
    "    # second layer of the DCB\n",
    "    l2_p1 = nn.Conv1d(feature_dim, feature_dim, kernel_size=5, padding=\"same\", dilation=2, bias=True)(l1_ELU)\n",
    "    l2_p2 = nn.Conv1d(feature_dim, feature_dim, kernel_size=5, padding=\"same\", dilation=2, bias=True)(l1_ELU)\n",
    "    # l2_add = Add()([l2_p1, l2_p2])\n",
    "    l2_ELU = nn.ELU()(l2_p1 + l2_p2)\n",
    "    # third layer of the DCB\n",
    "    l3_p1 = nn.Conv1d(feature_dim, feature_dim, kernel_size=9, padding=\"same\", dilation=4, bias=True)(l2_ELU)\n",
    "    l3_p2 = nn.Conv1d(feature_dim, feature_dim, kernel_size=9, padding=\"same\", dilation=4, bias=True)(l2_ELU)\n",
    "    # l3_add = Add()([l3_p1, l3_p2])\n",
    "    l3_ELU = nn.ELU()(l3_p1 + l3_p2)\n",
    "\n",
    "    residual = nn.Conv1d(input_dim, feature_dim, kernel_size=1, padding=\"same\")(inputs)\n",
    "    # res_add = Add()([l3_ELU, residual])\n",
    "    # res_add = Add()([l1_ELU, residual])\n",
    "    # res_add = ELU()(res_add)\n",
    "    bn = nn.BatchNorm1d(num_features=feature_dim)(l3_ELU + residual)\n",
    "    return bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "def time_diluted_conv_net(feature_dim, input_layer, pool_size, pool_stride):\n",
    "    dcb_1 = diluted_conv_block(input_layer, feature_dim[0], feature_dim[1])\n",
    "    mp_1 = nn.MaxPool1d(pool_size, stride=pool_stride)(dcb_1)\n",
    "    dcb_2 = diluted_conv_block(mp_1, feature_dim[1], feature_dim[2])\n",
    "    mp_2 = nn.MaxPool1d(pool_size, stride=pool_stride)(dcb_2)\n",
    "    dcb_3 = diluted_conv_block(mp_2, feature_dim[2], feature_dim[3])\n",
    "    mp_3 = nn.MaxPool1d(pool_size, stride=pool_stride)(dcb_3)\n",
    "    dcb_4 = diluted_conv_block(mp_3, feature_dim[3], feature_dim[4])\n",
    "    mp_4 = nn.MaxPool1d(pool_size, stride=pool_stride)(dcb_4)\n",
    "    dcb_5 = diluted_conv_block(mp_4, feature_dim[4], feature_dim[5])\n",
    "    return dcb_5\n",
    "\n",
    "tdcn_pose = time_diluted_conv_net(\n",
    "    feature_dim = tdcn_dim_pose, \n",
    "    input_layer = input_pose, \n",
    "    pool_size = 2, \n",
    "    pool_stride = 2,\n",
    "    )\n",
    "\n",
    "# concat = useful_layers.ConcatLayer([tdcn_pose])\n",
    "gap_layer = nn.AdaptiveMaxPool1d(1)(tdcn_pose)\n",
    "# print(gap_layer.shape)\n",
    "# linear_layer_1 = nn.Linear(gap_layer.shape[1], gap_layer.shape[1])(gap_layer)\n",
    "linear_layer_1 = nn.Linear(1, 1)(gap_layer)\n",
    "relu_layer = nn.ReLU()(linear_layer_1)\n",
    "# linear_layer_2 = nn.Linear(gap_layer.shape[1], gap_layer.shape[1])(relu_layer)\n",
    "linear_layer_2 = nn.Linear(1, 1)(relu_layer)\n",
    "sigmoid_layer = nn.Sigmoid()(linear_layer_2)\n",
    "reshape = sigmoid_layer\n",
    "for _ in range(0, tdcn_pose.shape[2]-1):\n",
    "    reshape = useful_layers.ConcatLayer(dim=2)(reshape, sigmoid_layer)\n",
    "# print(reshape.shape)\n",
    "# print(tdcn_pose.shape)\n",
    "# print((tdcn_pose*reshape).shape)\n",
    "flatten = nn.Flatten()(tdcn_pose*reshape)\n",
    "FC_l1 = nn.Linear(flatten.shape[1], 16)(flatten)(nn.ReLU())\n",
    "FC_l2 = nn.Linear(FC_l1.shape[1], 12)(FC_l1)(nn.ReLU())\n",
    "FC_l3 = nn.Linear(FC_l2.shape[1], 8)(FC_l2)(nn.ReLU())\n",
    "last_layer = nn.Linear(FC_l3.shape[1], 2)(FC_l3)(nn.ReLU())\n",
    "output = nn.Softmax(1)(last_layer)\n",
    "print(FC_l1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________\n",
      "       Layer                 Output shape        Params   Parent   \n",
      "===================================================================\n",
      "1      Input_1               (None, 6, 5000)     0                 \n",
      "2      Conv1d_1              (None, 128, 5000)   2432     1        \n",
      "3      Conv1d_2              (None, 128, 5000)   2432     1        \n",
      "4      AddOpLayer_1          (None, 128, 5000)   0        2,3      \n",
      "5      ELU_1                 (None, 128, 5000)   0        4        \n",
      "6      Conv1d_3              (None, 128, 5000)   82048    5        \n",
      "7      Conv1d_4              (None, 128, 5000)   82048    5        \n",
      "8      AddOpLayer_2          (None, 128, 5000)   0        6,7      \n",
      "9      ELU_2                 (None, 128, 5000)   0        8        \n",
      "10     Conv1d_5              (None, 128, 5000)   147584   9        \n",
      "11     Conv1d_6              (None, 128, 5000)   147584   9        \n",
      "12     AddOpLayer_3          (None, 128, 5000)   0        10,11    \n",
      "13     ELU_3                 (None, 128, 5000)   0        12       \n",
      "14     Conv1d_7              (None, 128, 5000)   896      1        \n",
      "15     AddOpLayer_4          (None, 128, 5000)   0        13,14    \n",
      "16     BatchNorm1d_1         (None, 128, 5000)   256      15       \n",
      "17     MaxPool1d_1           (None, 128, 2500)   0        16       \n",
      "18     Conv1d_8              (None, 64, 2500)    24640    17       \n",
      "19     Conv1d_9              (None, 64, 2500)    24640    17       \n",
      "20     AddOpLayer_5          (None, 64, 2500)    0        18,19    \n",
      "21     ELU_4                 (None, 64, 2500)    0        20       \n",
      "22     Conv1d_10             (None, 64, 2500)    20544    21       \n",
      "23     Conv1d_11             (None, 64, 2500)    20544    21       \n",
      "24     AddOpLayer_6          (None, 64, 2500)    0        22,23    \n",
      "25     ELU_5                 (None, 64, 2500)    0        24       \n",
      "26     Conv1d_12             (None, 64, 2500)    36928    25       \n",
      "27     Conv1d_13             (None, 64, 2500)    36928    25       \n",
      "28     AddOpLayer_7          (None, 64, 2500)    0        26,27    \n",
      "29     ELU_6                 (None, 64, 2500)    0        28       \n",
      "30     Conv1d_14             (None, 64, 2500)    8256     17       \n",
      "31     AddOpLayer_8          (None, 64, 2500)    0        29,30    \n",
      "32     BatchNorm1d_2         (None, 64, 2500)    128      31       \n",
      "33     MaxPool1d_2           (None, 64, 1250)    0        32       \n",
      "34     Conv1d_15             (None, 256, 1250)   49408    33       \n",
      "35     Conv1d_16             (None, 256, 1250)   49408    33       \n",
      "36     AddOpLayer_9          (None, 256, 1250)   0        34,35    \n",
      "37     ELU_7                 (None, 256, 1250)   0        36       \n",
      "38     Conv1d_17             (None, 256, 1250)   327936   37       \n",
      "39     Conv1d_18             (None, 256, 1250)   327936   37       \n",
      "40     AddOpLayer_10         (None, 256, 1250)   0        38,39    \n",
      "41     ELU_8                 (None, 256, 1250)   0        40       \n",
      "42     Conv1d_19             (None, 256, 1250)   590080   41       \n",
      "43     Conv1d_20             (None, 256, 1250)   590080   41       \n",
      "44     AddOpLayer_11         (None, 256, 1250)   0        42,43    \n",
      "45     ELU_9                 (None, 256, 1250)   0        44       \n",
      "46     Conv1d_21             (None, 256, 1250)   16640    33       \n",
      "47     AddOpLayer_12         (None, 256, 1250)   0        45,46    \n",
      "48     BatchNorm1d_3         (None, 256, 1250)   512      47       \n",
      "49     MaxPool1d_3           (None, 256, 625)    0        48       \n",
      "50     Conv1d_22             (None, 128, 625)    98432    49       \n",
      "51     Conv1d_23             (None, 128, 625)    98432    49       \n",
      "52     AddOpLayer_13         (None, 128, 625)    0        50,51    \n",
      "53     ELU_10                (None, 128, 625)    0        52       \n",
      "54     Conv1d_24             (None, 128, 625)    82048    53       \n",
      "55     Conv1d_25             (None, 128, 625)    82048    53       \n",
      "56     AddOpLayer_14         (None, 128, 625)    0        54,55    \n",
      "57     ELU_11                (None, 128, 625)    0        56       \n",
      "58     Conv1d_26             (None, 128, 625)    147584   57       \n",
      "59     Conv1d_27             (None, 128, 625)    147584   57       \n",
      "60     AddOpLayer_15         (None, 128, 625)    0        58,59    \n",
      "61     ELU_12                (None, 128, 625)    0        60       \n",
      "62     Conv1d_28             (None, 128, 625)    32896    49       \n",
      "63     AddOpLayer_16         (None, 128, 625)    0        61,62    \n",
      "64     BatchNorm1d_4         (None, 128, 625)    256      63       \n",
      "65     MaxPool1d_4           (None, 128, 312)    0        64       \n",
      "66     Conv1d_29             (None, 64, 312)     24640    65       \n",
      "67     Conv1d_30             (None, 64, 312)     24640    65       \n",
      "68     AddOpLayer_17         (None, 64, 312)     0        66,67    \n",
      "69     ELU_13                (None, 64, 312)     0        68       \n",
      "70     Conv1d_31             (None, 64, 312)     20544    69       \n",
      "71     Conv1d_32             (None, 64, 312)     20544    69       \n",
      "72     AddOpLayer_18         (None, 64, 312)     0        70,71    \n",
      "73     ELU_14                (None, 64, 312)     0        72       \n",
      "74     Conv1d_33             (None, 64, 312)     36928    73       \n",
      "75     Conv1d_34             (None, 64, 312)     36928    73       \n",
      "76     AddOpLayer_19         (None, 64, 312)     0        74,75    \n",
      "77     ELU_15                (None, 64, 312)     0        76       \n",
      "78     Conv1d_35             (None, 64, 312)     8256     65       \n",
      "79     AddOpLayer_20         (None, 64, 312)     0        77,78    \n",
      "80     BatchNorm1d_5         (None, 64, 312)     128      79       \n",
      "81     AdaptiveMaxPool1d_1   (None, 64, 1)       0        80       \n",
      "82     Linear_1              (None, 64, 1)       2        81       \n",
      "83     ReLU_1                (None, 64, 1)       0        82       \n",
      "84     Linear_2              (None, 64, 1)       2        83       \n",
      "85     Sigmoid_1             (None, 64, 1)       0        84       \n",
      "86     ConcatLayer_1         (None, 64, 2)       0        85,85    \n",
      "87     ConcatLayer_2         (None, 64, 3)       0        86,85    \n",
      "88     ConcatLayer_3         (None, 64, 4)       0        87,85    \n",
      "89     ConcatLayer_4         (None, 64, 5)       0        88,85    \n",
      "90     ConcatLayer_5         (None, 64, 6)       0        89,85    \n",
      "91     ConcatLayer_6         (None, 64, 7)       0        90,85    \n",
      "92     ConcatLayer_7         (None, 64, 8)       0        91,85    \n",
      "93     ConcatLayer_8         (None, 64, 9)       0        92,85    \n",
      "94     ConcatLayer_9         (None, 64, 10)      0        93,85    \n",
      "95     ConcatLayer_10        (None, 64, 11)      0        94,85    \n",
      "96     ConcatLayer_11        (None, 64, 12)      0        95,85    \n",
      "97     ConcatLayer_12        (None, 64, 13)      0        96,85    \n",
      "98     ConcatLayer_13        (None, 64, 14)      0        97,85    \n",
      "99     ConcatLayer_14        (None, 64, 15)      0        98,85    \n",
      "100    ConcatLayer_15        (None, 64, 16)      0        99,85    \n",
      "101    ConcatLayer_16        (None, 64, 17)      0        100,85   \n",
      "102    ConcatLayer_17        (None, 64, 18)      0        101,85   \n",
      "103    ConcatLayer_18        (None, 64, 19)      0        102,85   \n",
      "104    ConcatLayer_19        (None, 64, 20)      0        103,85   \n",
      "105    ConcatLayer_20        (None, 64, 21)      0        104,85   \n",
      "106    ConcatLayer_21        (None, 64, 22)      0        105,85   \n",
      "107    ConcatLayer_22        (None, 64, 23)      0        106,85   \n",
      "108    ConcatLayer_23        (None, 64, 24)      0        107,85   \n",
      "109    ConcatLayer_24        (None, 64, 25)      0        108,85   \n",
      "110    ConcatLayer_25        (None, 64, 26)      0        109,85   \n",
      "111    ConcatLayer_26        (None, 64, 27)      0        110,85   \n",
      "112    ConcatLayer_27        (None, 64, 28)      0        111,85   \n",
      "113    ConcatLayer_28        (None, 64, 29)      0        112,85   \n",
      "114    ConcatLayer_29        (None, 64, 30)      0        113,85   \n",
      "115    ConcatLayer_30        (None, 64, 31)      0        114,85   \n",
      "116    ConcatLayer_31        (None, 64, 32)      0        115,85   \n",
      "117    ConcatLayer_32        (None, 64, 33)      0        116,85   \n",
      "118    ConcatLayer_33        (None, 64, 34)      0        117,85   \n",
      "119    ConcatLayer_34        (None, 64, 35)      0        118,85   \n",
      "120    ConcatLayer_35        (None, 64, 36)      0        119,85   \n",
      "121    ConcatLayer_36        (None, 64, 37)      0        120,85   \n",
      "122    ConcatLayer_37        (None, 64, 38)      0        121,85   \n",
      "123    ConcatLayer_38        (None, 64, 39)      0        122,85   \n",
      "124    ConcatLayer_39        (None, 64, 40)      0        123,85   \n",
      "125    ConcatLayer_40        (None, 64, 41)      0        124,85   \n",
      "126    ConcatLayer_41        (None, 64, 42)      0        125,85   \n",
      "127    ConcatLayer_42        (None, 64, 43)      0        126,85   \n",
      "128    ConcatLayer_43        (None, 64, 44)      0        127,85   \n",
      "129    ConcatLayer_44        (None, 64, 45)      0        128,85   \n",
      "130    ConcatLayer_45        (None, 64, 46)      0        129,85   \n",
      "131    ConcatLayer_46        (None, 64, 47)      0        130,85   \n",
      "132    ConcatLayer_47        (None, 64, 48)      0        131,85   \n",
      "133    ConcatLayer_48        (None, 64, 49)      0        132,85   \n",
      "134    ConcatLayer_49        (None, 64, 50)      0        133,85   \n",
      "135    ConcatLayer_50        (None, 64, 51)      0        134,85   \n",
      "136    ConcatLayer_51        (None, 64, 52)      0        135,85   \n",
      "137    ConcatLayer_52        (None, 64, 53)      0        136,85   \n",
      "138    ConcatLayer_53        (None, 64, 54)      0        137,85   \n",
      "139    ConcatLayer_54        (None, 64, 55)      0        138,85   \n",
      "140    ConcatLayer_55        (None, 64, 56)      0        139,85   \n",
      "141    ConcatLayer_56        (None, 64, 57)      0        140,85   \n",
      "142    ConcatLayer_57        (None, 64, 58)      0        141,85   \n",
      "143    ConcatLayer_58        (None, 64, 59)      0        142,85   \n",
      "144    ConcatLayer_59        (None, 64, 60)      0        143,85   \n",
      "145    ConcatLayer_60        (None, 64, 61)      0        144,85   \n",
      "146    ConcatLayer_61        (None, 64, 62)      0        145,85   \n",
      "147    ConcatLayer_62        (None, 64, 63)      0        146,85   \n",
      "148    ConcatLayer_63        (None, 64, 64)      0        147,85   \n",
      "149    ConcatLayer_64        (None, 64, 65)      0        148,85   \n",
      "150    ConcatLayer_65        (None, 64, 66)      0        149,85   \n",
      "151    ConcatLayer_66        (None, 64, 67)      0        150,85   \n",
      "152    ConcatLayer_67        (None, 64, 68)      0        151,85   \n",
      "153    ConcatLayer_68        (None, 64, 69)      0        152,85   \n",
      "154    ConcatLayer_69        (None, 64, 70)      0        153,85   \n",
      "155    ConcatLayer_70        (None, 64, 71)      0        154,85   \n",
      "156    ConcatLayer_71        (None, 64, 72)      0        155,85   \n",
      "157    ConcatLayer_72        (None, 64, 73)      0        156,85   \n",
      "158    ConcatLayer_73        (None, 64, 74)      0        157,85   \n",
      "159    ConcatLayer_74        (None, 64, 75)      0        158,85   \n",
      "160    ConcatLayer_75        (None, 64, 76)      0        159,85   \n",
      "161    ConcatLayer_76        (None, 64, 77)      0        160,85   \n",
      "162    ConcatLayer_77        (None, 64, 78)      0        161,85   \n",
      "163    ConcatLayer_78        (None, 64, 79)      0        162,85   \n",
      "164    ConcatLayer_79        (None, 64, 80)      0        163,85   \n",
      "165    ConcatLayer_80        (None, 64, 81)      0        164,85   \n",
      "166    ConcatLayer_81        (None, 64, 82)      0        165,85   \n",
      "167    ConcatLayer_82        (None, 64, 83)      0        166,85   \n",
      "168    ConcatLayer_83        (None, 64, 84)      0        167,85   \n",
      "169    ConcatLayer_84        (None, 64, 85)      0        168,85   \n",
      "170    ConcatLayer_85        (None, 64, 86)      0        169,85   \n",
      "171    ConcatLayer_86        (None, 64, 87)      0        170,85   \n",
      "172    ConcatLayer_87        (None, 64, 88)      0        171,85   \n",
      "173    ConcatLayer_88        (None, 64, 89)      0        172,85   \n",
      "174    ConcatLayer_89        (None, 64, 90)      0        173,85   \n",
      "175    ConcatLayer_90        (None, 64, 91)      0        174,85   \n",
      "176    ConcatLayer_91        (None, 64, 92)      0        175,85   \n",
      "177    ConcatLayer_92        (None, 64, 93)      0        176,85   \n",
      "178    ConcatLayer_93        (None, 64, 94)      0        177,85   \n",
      "179    ConcatLayer_94        (None, 64, 95)      0        178,85   \n",
      "180    ConcatLayer_95        (None, 64, 96)      0        179,85   \n",
      "181    ConcatLayer_96        (None, 64, 97)      0        180,85   \n",
      "182    ConcatLayer_97        (None, 64, 98)      0        181,85   \n",
      "183    ConcatLayer_98        (None, 64, 99)      0        182,85   \n",
      "184    ConcatLayer_99        (None, 64, 100)     0        183,85   \n",
      "185    ConcatLayer_100       (None, 64, 101)     0        184,85   \n",
      "186    ConcatLayer_101       (None, 64, 102)     0        185,85   \n",
      "187    ConcatLayer_102       (None, 64, 103)     0        186,85   \n",
      "188    ConcatLayer_103       (None, 64, 104)     0        187,85   \n",
      "189    ConcatLayer_104       (None, 64, 105)     0        188,85   \n",
      "190    ConcatLayer_105       (None, 64, 106)     0        189,85   \n",
      "191    ConcatLayer_106       (None, 64, 107)     0        190,85   \n",
      "192    ConcatLayer_107       (None, 64, 108)     0        191,85   \n",
      "193    ConcatLayer_108       (None, 64, 109)     0        192,85   \n",
      "194    ConcatLayer_109       (None, 64, 110)     0        193,85   \n",
      "195    ConcatLayer_110       (None, 64, 111)     0        194,85   \n",
      "196    ConcatLayer_111       (None, 64, 112)     0        195,85   \n",
      "197    ConcatLayer_112       (None, 64, 113)     0        196,85   \n",
      "198    ConcatLayer_113       (None, 64, 114)     0        197,85   \n",
      "199    ConcatLayer_114       (None, 64, 115)     0        198,85   \n",
      "200    ConcatLayer_115       (None, 64, 116)     0        199,85   \n",
      "201    ConcatLayer_116       (None, 64, 117)     0        200,85   \n",
      "202    ConcatLayer_117       (None, 64, 118)     0        201,85   \n",
      "203    ConcatLayer_118       (None, 64, 119)     0        202,85   \n",
      "204    ConcatLayer_119       (None, 64, 120)     0        203,85   \n",
      "205    ConcatLayer_120       (None, 64, 121)     0        204,85   \n",
      "206    ConcatLayer_121       (None, 64, 122)     0        205,85   \n",
      "207    ConcatLayer_122       (None, 64, 123)     0        206,85   \n",
      "208    ConcatLayer_123       (None, 64, 124)     0        207,85   \n",
      "209    ConcatLayer_124       (None, 64, 125)     0        208,85   \n",
      "210    ConcatLayer_125       (None, 64, 126)     0        209,85   \n",
      "211    ConcatLayer_126       (None, 64, 127)     0        210,85   \n",
      "212    ConcatLayer_127       (None, 64, 128)     0        211,85   \n",
      "213    ConcatLayer_128       (None, 64, 129)     0        212,85   \n",
      "214    ConcatLayer_129       (None, 64, 130)     0        213,85   \n",
      "215    ConcatLayer_130       (None, 64, 131)     0        214,85   \n",
      "216    ConcatLayer_131       (None, 64, 132)     0        215,85   \n",
      "217    ConcatLayer_132       (None, 64, 133)     0        216,85   \n",
      "218    ConcatLayer_133       (None, 64, 134)     0        217,85   \n",
      "219    ConcatLayer_134       (None, 64, 135)     0        218,85   \n",
      "220    ConcatLayer_135       (None, 64, 136)     0        219,85   \n",
      "221    ConcatLayer_136       (None, 64, 137)     0        220,85   \n",
      "222    ConcatLayer_137       (None, 64, 138)     0        221,85   \n",
      "223    ConcatLayer_138       (None, 64, 139)     0        222,85   \n",
      "224    ConcatLayer_139       (None, 64, 140)     0        223,85   \n",
      "225    ConcatLayer_140       (None, 64, 141)     0        224,85   \n",
      "226    ConcatLayer_141       (None, 64, 142)     0        225,85   \n",
      "227    ConcatLayer_142       (None, 64, 143)     0        226,85   \n",
      "228    ConcatLayer_143       (None, 64, 144)     0        227,85   \n",
      "229    ConcatLayer_144       (None, 64, 145)     0        228,85   \n",
      "230    ConcatLayer_145       (None, 64, 146)     0        229,85   \n",
      "231    ConcatLayer_146       (None, 64, 147)     0        230,85   \n",
      "232    ConcatLayer_147       (None, 64, 148)     0        231,85   \n",
      "233    ConcatLayer_148       (None, 64, 149)     0        232,85   \n",
      "234    ConcatLayer_149       (None, 64, 150)     0        233,85   \n",
      "235    ConcatLayer_150       (None, 64, 151)     0        234,85   \n",
      "236    ConcatLayer_151       (None, 64, 152)     0        235,85   \n",
      "237    ConcatLayer_152       (None, 64, 153)     0        236,85   \n",
      "238    ConcatLayer_153       (None, 64, 154)     0        237,85   \n",
      "239    ConcatLayer_154       (None, 64, 155)     0        238,85   \n",
      "240    ConcatLayer_155       (None, 64, 156)     0        239,85   \n",
      "241    ConcatLayer_156       (None, 64, 157)     0        240,85   \n",
      "242    ConcatLayer_157       (None, 64, 158)     0        241,85   \n",
      "243    ConcatLayer_158       (None, 64, 159)     0        242,85   \n",
      "244    ConcatLayer_159       (None, 64, 160)     0        243,85   \n",
      "245    ConcatLayer_160       (None, 64, 161)     0        244,85   \n",
      "246    ConcatLayer_161       (None, 64, 162)     0        245,85   \n",
      "247    ConcatLayer_162       (None, 64, 163)     0        246,85   \n",
      "248    ConcatLayer_163       (None, 64, 164)     0        247,85   \n",
      "249    ConcatLayer_164       (None, 64, 165)     0        248,85   \n",
      "250    ConcatLayer_165       (None, 64, 166)     0        249,85   \n",
      "251    ConcatLayer_166       (None, 64, 167)     0        250,85   \n",
      "252    ConcatLayer_167       (None, 64, 168)     0        251,85   \n",
      "253    ConcatLayer_168       (None, 64, 169)     0        252,85   \n",
      "254    ConcatLayer_169       (None, 64, 170)     0        253,85   \n",
      "255    ConcatLayer_170       (None, 64, 171)     0        254,85   \n",
      "256    ConcatLayer_171       (None, 64, 172)     0        255,85   \n",
      "257    ConcatLayer_172       (None, 64, 173)     0        256,85   \n",
      "258    ConcatLayer_173       (None, 64, 174)     0        257,85   \n",
      "259    ConcatLayer_174       (None, 64, 175)     0        258,85   \n",
      "260    ConcatLayer_175       (None, 64, 176)     0        259,85   \n",
      "261    ConcatLayer_176       (None, 64, 177)     0        260,85   \n",
      "262    ConcatLayer_177       (None, 64, 178)     0        261,85   \n",
      "263    ConcatLayer_178       (None, 64, 179)     0        262,85   \n",
      "264    ConcatLayer_179       (None, 64, 180)     0        263,85   \n",
      "265    ConcatLayer_180       (None, 64, 181)     0        264,85   \n",
      "266    ConcatLayer_181       (None, 64, 182)     0        265,85   \n",
      "267    ConcatLayer_182       (None, 64, 183)     0        266,85   \n",
      "268    ConcatLayer_183       (None, 64, 184)     0        267,85   \n",
      "269    ConcatLayer_184       (None, 64, 185)     0        268,85   \n",
      "270    ConcatLayer_185       (None, 64, 186)     0        269,85   \n",
      "271    ConcatLayer_186       (None, 64, 187)     0        270,85   \n",
      "272    ConcatLayer_187       (None, 64, 188)     0        271,85   \n",
      "273    ConcatLayer_188       (None, 64, 189)     0        272,85   \n",
      "274    ConcatLayer_189       (None, 64, 190)     0        273,85   \n",
      "275    ConcatLayer_190       (None, 64, 191)     0        274,85   \n",
      "276    ConcatLayer_191       (None, 64, 192)     0        275,85   \n",
      "277    ConcatLayer_192       (None, 64, 193)     0        276,85   \n",
      "278    ConcatLayer_193       (None, 64, 194)     0        277,85   \n",
      "279    ConcatLayer_194       (None, 64, 195)     0        278,85   \n",
      "280    ConcatLayer_195       (None, 64, 196)     0        279,85   \n",
      "281    ConcatLayer_196       (None, 64, 197)     0        280,85   \n",
      "282    ConcatLayer_197       (None, 64, 198)     0        281,85   \n",
      "283    ConcatLayer_198       (None, 64, 199)     0        282,85   \n",
      "284    ConcatLayer_199       (None, 64, 200)     0        283,85   \n",
      "285    ConcatLayer_200       (None, 64, 201)     0        284,85   \n",
      "286    ConcatLayer_201       (None, 64, 202)     0        285,85   \n",
      "287    ConcatLayer_202       (None, 64, 203)     0        286,85   \n",
      "288    ConcatLayer_203       (None, 64, 204)     0        287,85   \n",
      "289    ConcatLayer_204       (None, 64, 205)     0        288,85   \n",
      "290    ConcatLayer_205       (None, 64, 206)     0        289,85   \n",
      "291    ConcatLayer_206       (None, 64, 207)     0        290,85   \n",
      "292    ConcatLayer_207       (None, 64, 208)     0        291,85   \n",
      "293    ConcatLayer_208       (None, 64, 209)     0        292,85   \n",
      "294    ConcatLayer_209       (None, 64, 210)     0        293,85   \n",
      "295    ConcatLayer_210       (None, 64, 211)     0        294,85   \n",
      "296    ConcatLayer_211       (None, 64, 212)     0        295,85   \n",
      "297    ConcatLayer_212       (None, 64, 213)     0        296,85   \n",
      "298    ConcatLayer_213       (None, 64, 214)     0        297,85   \n",
      "299    ConcatLayer_214       (None, 64, 215)     0        298,85   \n",
      "300    ConcatLayer_215       (None, 64, 216)     0        299,85   \n",
      "301    ConcatLayer_216       (None, 64, 217)     0        300,85   \n",
      "302    ConcatLayer_217       (None, 64, 218)     0        301,85   \n",
      "303    ConcatLayer_218       (None, 64, 219)     0        302,85   \n",
      "304    ConcatLayer_219       (None, 64, 220)     0        303,85   \n",
      "305    ConcatLayer_220       (None, 64, 221)     0        304,85   \n",
      "306    ConcatLayer_221       (None, 64, 222)     0        305,85   \n",
      "307    ConcatLayer_222       (None, 64, 223)     0        306,85   \n",
      "308    ConcatLayer_223       (None, 64, 224)     0        307,85   \n",
      "309    ConcatLayer_224       (None, 64, 225)     0        308,85   \n",
      "310    ConcatLayer_225       (None, 64, 226)     0        309,85   \n",
      "311    ConcatLayer_226       (None, 64, 227)     0        310,85   \n",
      "312    ConcatLayer_227       (None, 64, 228)     0        311,85   \n",
      "313    ConcatLayer_228       (None, 64, 229)     0        312,85   \n",
      "314    ConcatLayer_229       (None, 64, 230)     0        313,85   \n",
      "315    ConcatLayer_230       (None, 64, 231)     0        314,85   \n",
      "316    ConcatLayer_231       (None, 64, 232)     0        315,85   \n",
      "317    ConcatLayer_232       (None, 64, 233)     0        316,85   \n",
      "318    ConcatLayer_233       (None, 64, 234)     0        317,85   \n",
      "319    ConcatLayer_234       (None, 64, 235)     0        318,85   \n",
      "320    ConcatLayer_235       (None, 64, 236)     0        319,85   \n",
      "321    ConcatLayer_236       (None, 64, 237)     0        320,85   \n",
      "322    ConcatLayer_237       (None, 64, 238)     0        321,85   \n",
      "323    ConcatLayer_238       (None, 64, 239)     0        322,85   \n",
      "324    ConcatLayer_239       (None, 64, 240)     0        323,85   \n",
      "325    ConcatLayer_240       (None, 64, 241)     0        324,85   \n",
      "326    ConcatLayer_241       (None, 64, 242)     0        325,85   \n",
      "327    ConcatLayer_242       (None, 64, 243)     0        326,85   \n",
      "328    ConcatLayer_243       (None, 64, 244)     0        327,85   \n",
      "329    ConcatLayer_244       (None, 64, 245)     0        328,85   \n",
      "330    ConcatLayer_245       (None, 64, 246)     0        329,85   \n",
      "331    ConcatLayer_246       (None, 64, 247)     0        330,85   \n",
      "332    ConcatLayer_247       (None, 64, 248)     0        331,85   \n",
      "333    ConcatLayer_248       (None, 64, 249)     0        332,85   \n",
      "334    ConcatLayer_249       (None, 64, 250)     0        333,85   \n",
      "335    ConcatLayer_250       (None, 64, 251)     0        334,85   \n",
      "336    ConcatLayer_251       (None, 64, 252)     0        335,85   \n",
      "337    ConcatLayer_252       (None, 64, 253)     0        336,85   \n",
      "338    ConcatLayer_253       (None, 64, 254)     0        337,85   \n",
      "339    ConcatLayer_254       (None, 64, 255)     0        338,85   \n",
      "340    ConcatLayer_255       (None, 64, 256)     0        339,85   \n",
      "341    ConcatLayer_256       (None, 64, 257)     0        340,85   \n",
      "342    ConcatLayer_257       (None, 64, 258)     0        341,85   \n",
      "343    ConcatLayer_258       (None, 64, 259)     0        342,85   \n",
      "344    ConcatLayer_259       (None, 64, 260)     0        343,85   \n",
      "345    ConcatLayer_260       (None, 64, 261)     0        344,85   \n",
      "346    ConcatLayer_261       (None, 64, 262)     0        345,85   \n",
      "347    ConcatLayer_262       (None, 64, 263)     0        346,85   \n",
      "348    ConcatLayer_263       (None, 64, 264)     0        347,85   \n",
      "349    ConcatLayer_264       (None, 64, 265)     0        348,85   \n",
      "350    ConcatLayer_265       (None, 64, 266)     0        349,85   \n",
      "351    ConcatLayer_266       (None, 64, 267)     0        350,85   \n",
      "352    ConcatLayer_267       (None, 64, 268)     0        351,85   \n",
      "353    ConcatLayer_268       (None, 64, 269)     0        352,85   \n",
      "354    ConcatLayer_269       (None, 64, 270)     0        353,85   \n",
      "355    ConcatLayer_270       (None, 64, 271)     0        354,85   \n",
      "356    ConcatLayer_271       (None, 64, 272)     0        355,85   \n",
      "357    ConcatLayer_272       (None, 64, 273)     0        356,85   \n",
      "358    ConcatLayer_273       (None, 64, 274)     0        357,85   \n",
      "359    ConcatLayer_274       (None, 64, 275)     0        358,85   \n",
      "360    ConcatLayer_275       (None, 64, 276)     0        359,85   \n",
      "361    ConcatLayer_276       (None, 64, 277)     0        360,85   \n",
      "362    ConcatLayer_277       (None, 64, 278)     0        361,85   \n",
      "363    ConcatLayer_278       (None, 64, 279)     0        362,85   \n",
      "364    ConcatLayer_279       (None, 64, 280)     0        363,85   \n",
      "365    ConcatLayer_280       (None, 64, 281)     0        364,85   \n",
      "366    ConcatLayer_281       (None, 64, 282)     0        365,85   \n",
      "367    ConcatLayer_282       (None, 64, 283)     0        366,85   \n",
      "368    ConcatLayer_283       (None, 64, 284)     0        367,85   \n",
      "369    ConcatLayer_284       (None, 64, 285)     0        368,85   \n",
      "370    ConcatLayer_285       (None, 64, 286)     0        369,85   \n",
      "371    ConcatLayer_286       (None, 64, 287)     0        370,85   \n",
      "372    ConcatLayer_287       (None, 64, 288)     0        371,85   \n",
      "373    ConcatLayer_288       (None, 64, 289)     0        372,85   \n",
      "374    ConcatLayer_289       (None, 64, 290)     0        373,85   \n",
      "375    ConcatLayer_290       (None, 64, 291)     0        374,85   \n",
      "376    ConcatLayer_291       (None, 64, 292)     0        375,85   \n",
      "377    ConcatLayer_292       (None, 64, 293)     0        376,85   \n",
      "378    ConcatLayer_293       (None, 64, 294)     0        377,85   \n",
      "379    ConcatLayer_294       (None, 64, 295)     0        378,85   \n",
      "380    ConcatLayer_295       (None, 64, 296)     0        379,85   \n",
      "381    ConcatLayer_296       (None, 64, 297)     0        380,85   \n",
      "382    ConcatLayer_297       (None, 64, 298)     0        381,85   \n",
      "383    ConcatLayer_298       (None, 64, 299)     0        382,85   \n",
      "384    ConcatLayer_299       (None, 64, 300)     0        383,85   \n",
      "385    ConcatLayer_300       (None, 64, 301)     0        384,85   \n",
      "386    ConcatLayer_301       (None, 64, 302)     0        385,85   \n",
      "387    ConcatLayer_302       (None, 64, 303)     0        386,85   \n",
      "388    ConcatLayer_303       (None, 64, 304)     0        387,85   \n",
      "389    ConcatLayer_304       (None, 64, 305)     0        388,85   \n",
      "390    ConcatLayer_305       (None, 64, 306)     0        389,85   \n",
      "391    ConcatLayer_306       (None, 64, 307)     0        390,85   \n",
      "392    ConcatLayer_307       (None, 64, 308)     0        391,85   \n",
      "393    ConcatLayer_308       (None, 64, 309)     0        392,85   \n",
      "394    ConcatLayer_309       (None, 64, 310)     0        393,85   \n",
      "395    ConcatLayer_310       (None, 64, 311)     0        394,85   \n",
      "396    ConcatLayer_311       (None, 64, 312)     0        395,85   \n",
      "397    MulOpLayer_1          (None, 64, 312)     0        80,396   \n",
      "398    Flatten_1             (None, 19968)       0        397      \n",
      "399    Linear_3              (None, 16)          319504   398      \n",
      "400    ReLU_2                (None, 16)          0        399      \n",
      "401    Linear_4              (None, 12)          204      400      \n",
      "402    ReLU_3                (None, 12)          0        401      \n",
      "403    Linear_5              (None, 8)           104      402      \n",
      "404    ReLU_4                (None, 8)           0        403      \n",
      "405    Linear_6              (None, 2)           18       404      \n",
      "406    ReLU_5                (None, 2)           0        405      \n",
      "407*   Softmax_1             (None, 2)           0        406      \n",
      "===================================================================\n",
      "Total params: 3771610\n",
      "Trainable params: 3771610\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "model = SymbolicModel(inputs=input_pose, outputs=output).to(device)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADD2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
