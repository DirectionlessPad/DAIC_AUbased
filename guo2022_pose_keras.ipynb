{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 413,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "from imblearn.over_sampling import RandomOverSampler\n",
                "from keras.models import load_model\n",
                "from keras.callbacks import ModelCheckpoint\n",
                "from keras.layers import BatchNormalization, Dense, Input, Conv1D, Add, ELU, Flatten, MaxPooling1D\n",
                "from keras.layers import GlobalAveragePooling1D, Softmax, Concatenate, Reshape, Multiply, ReLU, Dropout\n",
                "from keras.optimizers import SGD\n",
                "from keras import activations\n",
                "from keras import Model\n",
                "from keras.initializers import HeNormal\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "from load_dataset import load_original_daic, load_labels\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from keras.utils.vis_utils import plot_model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 414,
            "metadata": {},
            "outputs": [],
            "source": [
                "daic_pose_train = load_original_daic(\"original_daic/train\", \"pose\")\n",
                "daic_pose_dev = load_original_daic(\"original_daic/dev\", \"pose\")\n",
                "daic_pose_test = load_original_daic(\"original_daic/test\", \"pose\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 415,
            "metadata": {},
            "outputs": [],
            "source": [
                "# daic_pose_dev[\"432\"].loc[0:4999]\n",
                "# for i in range(5000):\n",
                "#     try:\n",
                "#         temp = daic_pose_test[\"432\"].loc[i].to_numpy(dtype=\"float32\")\n",
                "#     except Exception:\n",
                "#         print(i)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 416,
            "metadata": {},
            "outputs": [],
            "source": [
                "label_path = Path(\"original_daic/labels\")\n",
                "loaded_labels = load_labels(label_path)\n",
                "y_train = np.array(loaded_labels[\"train\"])\n",
                "y_dev = np.array(loaded_labels[\"dev\"])\n",
                "y_test = np.array(loaded_labels[\"test\"])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 417,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train_depressed_idx = np.where(y_train==1)[0]\n",
                "# dev_depressed_idx = np.where(y_dev==1)[0]\n",
                "# test_depressed_idx = np.where(y_test==1)[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 418,
            "metadata": {},
            "outputs": [],
            "source": [
                "pose_train = []\n",
                "pose_dev = []\n",
                "pose_test = []\n",
                "for subject_id, subject_df in daic_pose_train.items():\n",
                "    temp = subject_df.copy().loc[1000:5999].to_numpy(dtype=\"float32\")\n",
                "    pose_train.append(temp)\n",
                "for subject_id, subject_df in daic_pose_dev.items():\n",
                "    # print(subject_id)\n",
                "    temp = subject_df.copy().loc[1000:5999].to_numpy(dtype=\"float32\")\n",
                "    pose_dev.append(temp)\n",
                "for subject_id, subject_df in daic_pose_test.items():\n",
                "    # print(subject_id)\n",
                "    temp = subject_df.copy().loc[1000:5999].to_numpy(dtype=\"float32\")\n",
                "    pose_test.append(temp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 419,
            "metadata": {},
            "outputs": [],
            "source": [
                "# list1 = [np.array([12,1]), np.array([2,3])]\n",
                "# list2 = [np.array([4,5]), np.array([6,7])]\n",
                "# list3 = [np.array([8,9]), np.array([10,11])]\n",
                "# all_lists = np.array(list1 + list2 + list3)\n",
                "# print(all_lists.min(0))\n",
                "# print(all_lists.ptp(0))\n",
                "all_samples = pose_train + pose_dev + pose_test\n",
                "# all_samples = np.array(pose_train + pose_dev + pose_test, dtype=object)\n",
                "all_samples = np.concatenate((all_samples),)\n",
                "# all_samples.shape\n",
                "min_values = all_samples.min(axis=0)\n",
                "ptp_ranges = all_samples.ptp(axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 420,
            "metadata": {},
            "outputs": [],
            "source": [
                "pose_train = np.array(pose_train)\n",
                "pose_dev = np.array(pose_dev)\n",
                "pose_test = np.array(pose_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 421,
            "metadata": {},
            "outputs": [],
            "source": [
                "norm_pose_train = (pose_train - min_values)/ptp_ranges\n",
                "norm_pose_dev = (pose_dev - min_values)/ptp_ranges\n",
                "norm_pose_test = (pose_test - min_values)/ptp_ranges"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 422,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(47,)\n",
                        "30\n"
                    ]
                }
            ],
            "source": [
                "print(y_test.shape)\n",
                "print(sum(y_train))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 423,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "154\n"
                    ]
                }
            ],
            "source": [
                "# depressed_only = norm_pose_train[train_depressed_idx]\n",
                "indices = range(norm_pose_train.shape[0])\n",
                "oversample = RandomOverSampler(sampling_strategy='minority')\n",
                "# oversample = RandomOverSampler(sampling_strategy=0.75)\n",
                "# print(norm_pose_train[:].shape)\n",
                "indices = np.array(indices).reshape(-1,1)\n",
                "ros_indices, _ = oversample.fit_resample(indices, y_train)\n",
                "print(len(ros_indices))\n",
                "rng = np.random.default_rng(10000)\n",
                "rng.shuffle(ros_indices)\n",
                "ros_norm_pose_train = np.squeeze(norm_pose_train[ros_indices])\n",
                "over_train_y = np.squeeze(y_train[ros_indices])\n",
                "# print(ros_norm_pose_train.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 424,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1\n",
                        " 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1\n",
                        " 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 0\n",
                        " 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
                        " 0 1 0 1 1 1]\n"
                    ]
                }
            ],
            "source": [
                "print(over_train_y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 425,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_pose = Input(shape=[5000, 6])\n",
                "tdcn_dim_pose = [128,64,256,128,64] # used in Guo's paper\n",
                "# tdcn_dim_pose = [128,128,128,128,128]\n",
                "bias_initializer = HeNormal(seed=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 426,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(400, 5000, 6)\n",
                        "(400,)\n"
                    ]
                }
            ],
            "source": [
                "x_train_bad = np.concatenate((np.zeros((200, 5000, 6)), np.ones((200, 5000, 6))))\n",
                "y_train_bad = np.concatenate((np.zeros(200), np.ones(200)))\n",
                "x_dev_bad = np.concatenate((np.zeros((20, 5000, 6)), np.ones((20, 5000, 6))))\n",
                "y_dev_bad = np.concatenate((np.zeros(20), np.ones(20)))\n",
                "rng = np.random.default_rng(12345)\n",
                "order = np.arange(0,400)\n",
                "rng.shuffle(order)\n",
                "x_train_bad = x_train_bad[order]\n",
                "y_train_bad = y_train_bad[order]\n",
                "print(x_train_bad.shape)\n",
                "print(y_train_bad.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 427,
            "metadata": {},
            "outputs": [],
            "source": [
                "# One DCB\n",
                "# first layer of the DCB\n",
                "def diluted_conv_block(inputs, feature_dim, batch_normalisation=False):\n",
                "    # with K.name_scope(block_name)\n",
                "    l1_p1 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=1, use_bias=True, bias_initializer=bias_initializer)(inputs)\n",
                "    l1_p2 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=1, use_bias=True, bias_initializer=bias_initializer)(inputs)\n",
                "    l1_add = Add()([l1_p1, l1_p2])\n",
                "    l1_ELU = ELU()(l1_add)\n",
                "    # second layer of the DCB\n",
                "    # l2_p1 = Conv1D(filters=feature_dim, kernel_size=5, padding=\"same\", dilation_rate=2, use_bias=True, bias_initializer=bias_initializer)(l1_ELU)\n",
                "    # l2_p2 = Conv1D(filters=feature_dim, kernel_size=5, padding=\"same\", dilation_rate=2, use_bias=True, bias_initializer=bias_initializer)(l1_ELU)\n",
                "    l2_p1 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=2, use_bias=True, bias_initializer=bias_initializer)(l1_ELU)\n",
                "    l2_p2 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=2, use_bias=True, bias_initializer=bias_initializer)(l1_ELU)\n",
                "    l2_add = Add()([l2_p1, l2_p2])\n",
                "    l2_ELU = ELU()(l2_add)\n",
                "    # third layer of the DCB\n",
                "    # l3_p1 = Conv1D(filters=feature_dim, kernel_size=9, padding=\"same\", dilation_rate=4, use_bias=True, bias_initializer=bias_initializer)(l2_ELU)\n",
                "    # l3_p2 = Conv1D(filters=feature_dim, kernel_size=9, padding=\"same\", dilation_rate=4, use_bias=True, bias_initializer=bias_initializer)(l2_ELU)\n",
                "    l3_p1 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=4, use_bias=True, bias_initializer=bias_initializer)(l2_ELU)\n",
                "    l3_p2 = Conv1D(filters=feature_dim, kernel_size=3, padding=\"same\", dilation_rate=4, use_bias=True, bias_initializer=bias_initializer)(l2_ELU)\n",
                "    l3_add = Add()([l3_p1, l3_p2])\n",
                "    l3_ELU = ELU()(l3_add)\n",
                "\n",
                "    residual = Conv1D(filters=feature_dim, kernel_size=1, padding=\"same\")(inputs)\n",
                "    res_add = Add()([l3_ELU, residual])\n",
                "    if batch_normalisation:\n",
                "        bn = BatchNormalization()(res_add)\n",
                "        return bn\n",
                "    else:\n",
                "        return res_add"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 428,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(None, 312, 64)\n",
                        "(None, 19968)\n"
                    ]
                }
            ],
            "source": [
                "def time_diluted_conv_net(feature_dim, input_layer, pool_size, pool_stride):\n",
                "    dcb_1 = diluted_conv_block(input_layer, feature_dim[0], batch_normalisation=True)\n",
                "    mp_1 = MaxPooling1D(pool_size=pool_size, strides=pool_stride, padding='valid')(dcb_1)\n",
                "    dcb_2 = diluted_conv_block(mp_1, feature_dim[1], batch_normalisation=True)\n",
                "    mp_2 = MaxPooling1D(pool_size=pool_size, strides=pool_stride, padding='valid')(dcb_2)\n",
                "    dcb_3 = diluted_conv_block(mp_2, feature_dim[2], batch_normalisation=True)\n",
                "    mp_3 = MaxPooling1D(pool_size=pool_size, strides=pool_stride, padding='valid')(dcb_3)\n",
                "    dcb_4 = diluted_conv_block(mp_3, feature_dim[3], batch_normalisation=True)\n",
                "    mp_4 = MaxPooling1D(pool_size=pool_size, strides=pool_stride, padding='valid')(dcb_4)\n",
                "    dcb_5 = diluted_conv_block(mp_4, feature_dim[4], batch_normalisation=False)\n",
                "    return dcb_5\n",
                "    # return dcb_2\n",
                "\n",
                "# TDCN block for pose\n",
                "tdcn_pose = time_diluted_conv_net(\n",
                "    feature_dim = tdcn_dim_pose, \n",
                "    input_layer = input_pose, \n",
                "    pool_size = 2, \n",
                "    pool_stride = 2,\n",
                "    )\n",
                "\n",
                "# FWA block\n",
                "concat_layer = Concatenate()([tdcn_pose])\n",
                "# print(concat_layer.shape)\n",
                "# gap_layer = GlobalAveragePooling1D(data_format=\"channels_last\")(concat_layer)\n",
                "gap_layer = GlobalAveragePooling1D(data_format=\"channels_last\")(tdcn_pose)\n",
                "# print(gap_layer.shape)\n",
                "\n",
                "linear_layer_1 = Dense(gap_layer.shape[1])(gap_layer)\n",
                "# relu_layer = Dense(128, activation = \"relu\")(linear_layer_1)\n",
                "relu_layer = activations.relu(linear_layer_1)\n",
                "# relu_layer = ReLU()(linear_layer_1)\n",
                "linear_layer_2 = Dense(gap_layer.shape[1])(relu_layer)\n",
                "# sigmoid_layer = Dense(128, activation = \"sigmoid\")(linear_layer_2)\n",
                "sigmoid_layer = activations.sigmoid(linear_layer_2)\n",
                "# reshape_layer = Reshape((312, 128),)(sigmoid_layer)\n",
                "# print(reshape_layer.output_shape)\n",
                "# elementwise_product = Multiply()([concat_layer, reshape_layer])\n",
                "# elementwise_product = Multiply()([concat_layer, sigmoid_layer])\n",
                "elementwise_product = Multiply()([tdcn_pose, sigmoid_layer])\n",
                "print(elementwise_product.shape)\n",
                "# FC layer\n",
                "flatten = Flatten()(elementwise_product)\n",
                "print(flatten.shape)\n",
                "# the default (but should it be?)\n",
                "# FC_l1 = Dense(16, activation=\"relu\")(flatten)\n",
                "# FC_l2 = Dense(12, activation=\"relu\")(FC_l1)\n",
                "# FC_l3 = Dense(8, activation=\"relu\")(FC_l2)\n",
                "# last_layer = Dense(2, activation=\"relu\")(FC_l3)\n",
                "\n",
                "# FC_l1 = Dense(64, activation=\"relu\")(flatten)\n",
                "# FC_l2 = Dense(32, activation=\"relu\")(FC_l1)\n",
                "# FC_l3 = Dense(16, activation=\"relu\")(FC_l2)\n",
                "# last_layer = Dense(2, activation=\"relu\")(FC_l3)\n",
                "\n",
                "FC_l1 = Dense(15000)(flatten)\n",
                "FC_l2 = Dense(9000)(FC_l1)\n",
                "# FC_l3 = Dense(320, activation=\"relu\")(FC_l2)\n",
                "# FC_l4 = Dense(80, activation=\"relu\")(FC_l3)\n",
                "last_layer = Dense(2)(FC_l2)\n",
                "\n",
                "# FC_l1 = Dense(16, activation=\"relu\")(flatten)\n",
                "# drop_1 = Dropout(0.2)(FC_l1)\n",
                "# FC_l2 = Dense(16, activation=\"relu\")(drop_1)\n",
                "# drop_2 = Dropout(0.2)(FC_l2)\n",
                "# FC_l3 = Dense(8, activation=\"relu\")(drop_2)\n",
                "# drop_3 = Dropout(0.2)(FC_l3)\n",
                "# last_layer = Dense(2, activation=\"relu\")(drop_3)\n",
                "\n",
                "# FC_l1 = Dense(100, activation=\"relu\")(flatten)\n",
                "# FC_l2 = Dense(15, activation=\"relu\")(FC_l1)\n",
                "# # FC_l3 = Dense(30, activation=\"relu\")(FC_l2)\n",
                "# last_layer = Dense(2, activation=\"relu\")(FC_l2)\n",
                "\n",
                "output = Softmax()(last_layer)\n",
                "# output = Dense(1, activation = \"sigmoid\")(FC_l3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 429,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 8\n",
                "checkpoint_path = \"training_ckpts/keras/pose/pose_training_E-{epoch:04d}.ckpt\"\n",
                "checkpoint_dir = Path(checkpoint_path)\n",
                "\n",
                "cp_callback = ModelCheckpoint(filepath=checkpoint_dir, save_weights_only=True, save_freq=5*batch_size, verbose=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 430,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_pose = Model(inputs=[input_pose], outputs=[output])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 431,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model_pose = load_model(\"saved_models/good_pose_5_7\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 432,
            "metadata": {},
            "outputs": [],
            "source": [
                "# in this instance was using kernel_size=3 for all conv layers and 16,12,8,2 for the FC layers\n",
                "# model_pose.load_weights(\"training_ckpts\\pose_training_C2-0005.ckpt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 433,
            "metadata": {},
            "outputs": [],
            "source": [
                "opt = SGD(learning_rate = 2e-5, momentum = 0.9)\n",
                "# opt = SGD(learning_rate = 2e-5, momentum = 0.9, nesterov=True)\n",
                "# opt = SGD(learning_rate = 2e-6, momentum = 0.05)\n",
                "model_pose.compile(loss = \"binary_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
                "# model_pose.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
                "# model_pose.save_weights(checkpoint_path.format(epoch=0))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 434,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/20\n",
                        "20/20 [==============================] - 82s 4s/step - loss: 0.9790 - accuracy: 0.4221 - val_loss: 1.0612 - val_accuracy: 0.6571\n",
                        "Epoch 2/20\n",
                        "19/20 [===========================>..] - ETA: 3s - loss: 0.8615 - accuracy: 0.4539\n",
                        "Epoch 2: saving model to training_ckpts\\pose_training_D-0002.ckpt\n",
                        "20/20 [==============================] - 91s 5s/step - loss: 0.8595 - accuracy: 0.4545 - val_loss: 0.7903 - val_accuracy: 0.6571\n",
                        "Epoch 3/20\n",
                        "20/20 [==============================] - 71s 4s/step - loss: 0.7931 - accuracy: 0.5844 - val_loss: 0.7206 - val_accuracy: 0.6571\n",
                        "Epoch 4/20\n",
                        "19/20 [===========================>..] - ETA: 3s - loss: 0.7748 - accuracy: 0.4145\n",
                        "Epoch 4: saving model to training_ckpts\\pose_training_D-0004.ckpt\n",
                        "20/20 [==============================] - 88s 4s/step - loss: 0.7797 - accuracy: 0.4156 - val_loss: 0.7560 - val_accuracy: 0.6571\n",
                        "Epoch 5/20\n",
                        "20/20 [==============================] - 72s 4s/step - loss: 0.7778 - accuracy: 0.4935 - val_loss: 1.0764 - val_accuracy: 0.6571\n",
                        "Epoch 6/20\n",
                        "19/20 [===========================>..] - ETA: 3s - loss: 0.7569 - accuracy: 0.4605\n",
                        "Epoch 6: saving model to training_ckpts\\pose_training_D-0006.ckpt\n",
                        "20/20 [==============================] - 87s 4s/step - loss: 0.7568 - accuracy: 0.4675 - val_loss: 0.7848 - val_accuracy: 0.6571\n",
                        "Epoch 7/20\n",
                        "20/20 [==============================] - 70s 4s/step - loss: 0.7793 - accuracy: 0.4870 - val_loss: 0.9744 - val_accuracy: 0.6571\n",
                        "Epoch 8/20\n",
                        "19/20 [===========================>..] - ETA: 3s - loss: 0.7758 - accuracy: 0.4013\n",
                        "Epoch 8: saving model to training_ckpts\\pose_training_D-0008.ckpt\n",
                        "20/20 [==============================] - 85s 4s/step - loss: 0.7753 - accuracy: 0.4026 - val_loss: 0.9015 - val_accuracy: 0.6571\n",
                        "Epoch 9/20\n",
                        "20/20 [==============================] - 72s 4s/step - loss: 0.7586 - accuracy: 0.6104 - val_loss: 1.0168 - val_accuracy: 0.6571\n",
                        "Epoch 10/20\n",
                        "19/20 [===========================>..] - ETA: 2s - loss: 0.7534 - accuracy: 0.4868\n",
                        "Epoch 10: saving model to training_ckpts\\pose_training_D-0010.ckpt\n",
                        "20/20 [==============================] - 71s 4s/step - loss: 0.7578 - accuracy: 0.4935 - val_loss: 0.8846 - val_accuracy: 0.6571\n",
                        "Epoch 11/20\n",
                        "20/20 [==============================] - 74s 4s/step - loss: 0.7620 - accuracy: 0.5195 - val_loss: 0.8916 - val_accuracy: 0.6571\n",
                        "Epoch 12/20\n",
                        "19/20 [===========================>..] - ETA: 3s - loss: 0.7632 - accuracy: 0.4145\n",
                        "Epoch 12: saving model to training_ckpts\\pose_training_D-0012.ckpt\n",
                        "20/20 [==============================] - 84s 4s/step - loss: 0.7627 - accuracy: 0.4156 - val_loss: 0.8746 - val_accuracy: 0.6571\n",
                        "Epoch 13/20\n",
                        "20/20 [==============================] - 71s 4s/step - loss: 0.7772 - accuracy: 0.4805 - val_loss: 0.7738 - val_accuracy: 0.6571\n",
                        "Epoch 14/20\n",
                        "14/20 [====================>.........] - ETA: 21s - loss: 0.7380 - accuracy: 0.5536"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[434], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# model_pose.fit(x_train_bad[:], y_train_bad[:], validation_data=(x_dev_bad[:], y_dev_bad[:]), epochs=4)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# model_pose.fit(norm_pose_train[:], y_train[:], validation_data=(norm_pose_dev[:], y_dev[:]), epochs=6, batch_size=8)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model_pose\u001b[39m.\u001b[39;49mfit(ros_norm_pose_train[:], over_train_y, validation_data\u001b[39m=\u001b[39;49m(norm_pose_dev[:], y_dev[:]), epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size, callbacks\u001b[39m=\u001b[39;49m[cp_callback])\n\u001b[0;32m      4\u001b[0m \u001b[39m# model_pose.fit(ros_norm_pose_train[:], over_train_y, validation_data=(norm_pose_dev[:], y_dev[:]), epochs=4, callbacks=[cp_callback])\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# model_pose.fit(ros_norm_pose_train[:], over_train_y, validation_data=(norm_pose_dev[:], y_dev[:]), epochs=10, batch_size=batch_size)\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
                        "File \u001b[1;32mc:\\Users\\u1737136\\Anaconda3\\envs\\attempt2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# model_pose.fit(x_train_bad[:], y_train_bad[:], validation_data=(x_dev_bad[:], y_dev_bad[:]), epochs=4)\n",
                "# model_pose.fit(norm_pose_train[:], y_train[:], validation_data=(norm_pose_dev[:], y_dev[:]), epochs=6, batch_size=8)\n",
                "model_pose.fit(ros_norm_pose_train[:], over_train_y, validation_data=(norm_pose_dev[:], y_dev[:]), epochs=20, batch_size=batch_size, callbacks=[cp_callback])\n",
                "# model_pose.fit(ros_norm_pose_train[:], over_train_y, validation_data=(norm_pose_dev[:], y_dev[:]), epochs=4, callbacks=[cp_callback])\n",
                "# model_pose.fit(ros_norm_pose_train[:], over_train_y, validation_data=(norm_pose_dev[:], y_dev[:]), epochs=10, batch_size=batch_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.5\n",
                        "0.2803738317757009\n",
                        "0.34285714285714286\n",
                        "0.2978723404255319\n"
                    ]
                }
            ],
            "source": [
                "# model_pose.evaluate(x=pose_test, y=y_test)\n",
                "print(sum(over_train_y)/len(over_train_y))\n",
                "print(sum(y_train)/len(y_train))\n",
                "print(sum(y_dev)/len(y_dev))\n",
                "print(sum(y_test)/len(y_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2/2 [==============================] - 2s 302ms/step\n",
                        "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
                        "[[0.         0.65714286]\n",
                        " [0.         0.34285714]]\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGwCAYAAAB1mRuuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP00lEQVR4nO3deViUVfsH8O8M27ANiCibLKKxaAoIimRmFgaVhppJRT+Q1HpTwiRLfUvAFcs1y1wTsvSVMrNyoZTStCgTFS0RFRdQAXcRVJaZ8/uDmJoAY5hhcOD7ua7ninnmnOecmUBuzn0/ZyRCCAEiIiIi0hlpS0+AiIiIqLVhgEVERESkYwywiIiIiHSMARYRERGRjjHAIiIiItIxBlhEREREOsYAi4iIiEjHjFt6AmT4lEolLly4AGtra0gkkpaeDhERaUAIgZs3b8LZ2RlSafOtu9y5cweVlZVaX8fU1BQymUwHM2peDLBIaxcuXICrq2tLT4OIiLRQWFiITp06Ncu179y5g87uVii+qND6Wo6Ojjh9+vQ9H2QxwCKtWVtbAwAexBMwhkkLz4aoeXx5/EhLT4GoWZSWKeHe64zq3/LmUFlZieKLCpzN9oDcuumrZKU3lXAPPIPKykoGWNT61aYFjWECYwkDLGqdtPmlQGQI9FHiYWUtgZV108dRwnDKUBhgERERkV4ohBIKLT4BWSGUuptMM2OARURERHqhhIASTY+wtOmrb1zzJiIiItIxrmARERGRXiihhDZJPu166xcDLCIiItILhRBQiKan+bTpq29MERIRERHpGFewiIiISC/aUpE7AywiIiLSCyUEFG0kwGKKkIiIiEjHuIJFREREesEUIREREZGO8S5CIiIiImoyrmARERGRXij/PLTpbygYYBEREZFeKLS8i1CbvvrGAIuIiIj0QiFqDm36GwrWYBERERHpGFewiIiISC9Yg0VERESkY0pIoIBEq/6GgilCIiIiIh3jChYRERHphVLUHNr0NxQMsIiIiEgvFFqmCLXpq29MERIRERHpGFewiIiISC/a0goWAywiIiLSC6WQQCm0uItQi776xhQhERERkY5xBYuIiIj0oi2lCLmCRURERHqhgFTroymWLl0KDw8PyGQyBAcHY9++fXdtf/36dYwfPx5OTk4wMzODl5cXtm3bptGYXMEiIiIivRBa1mCJJvRNT09HQkICli9fjuDgYCxevBhhYWHIy8tDx44d67SvrKzEoEGD0LFjR2zcuBEuLi44e/YsbG1tNRqXARYREREZlNLSUrXHZmZmMDMzq7ftwoULMXbsWMTGxgIAli9fjq1bt2LNmjWYMmVKnfZr1qzB1atX8fPPP8PExAQA4OHhofEcmSIkIiIivaitwdLmAABXV1fY2NiojpSUlHrHq6ysRHZ2NkJDQ1XnpFIpQkNDkZWVVW+fr7/+GiEhIRg/fjwcHBxw//33Y86cOVAoFBq9Vq5gERERkV4ohBQK0fS1HcWfH5VTWFgIuVyuOt/Q6tXly5ehUCjg4OCgdt7BwQHHjh2rt8+pU6fw/fffIyoqCtu2bcPJkycxbtw4VFVVISkpqdFzZYBFREREBkUul6sFWLqkVCrRsWNHrFy5EkZGRggMDMT58+cxb948BlhERER071FCAqUW1UlKaPZpz/b29jAyMkJJSYna+ZKSEjg6Otbbx8nJCSYmJjAyMlKd8/X1RXFxMSorK2FqatqosVmDRURERHqhqxqsxjI1NUVgYCAyMzNV55RKJTIzMxESElJvn379+uHkyZNQKpWqc8ePH4eTk1OjgyuAARYRERG1YgkJCVi1ahU+/vhj5Obm4pVXXkF5ebnqrsLo6GhMnTpV1f6VV17B1atXMWHCBBw/fhxbt27FnDlzMH78eI3GZYqQiIiI9EL7InfNUoQAEBkZiUuXLiExMRHFxcXw9/dHRkaGqvC9oKAAUulfc3J1dcW3336LiRMnomfPnnBxccGECRMwefJkjcaVCNGE2RL9TWlpKWxsbPAwImAsMWnp6RA1i28vHGrpKRA1i9KbSrTzOoUbN240W+F47e+JL3K8YGlt9O8dGlB+U4Gn/Y4361x1hSlCIiIiIh1jipCIiIj0QqnF5wnW9DecpBsDLCIiItKLlqjBaikMsIiIiEgvlJDqdR+slsQaLCIiIiId4woWERER6YVCSKAQmm0W+s/+hoIBFhEREemFQssidwVThERERERtF1ewiIiISC+UQgqlFncRKnkXIREREZE6pgiJiIiIqMm4gkVERER6oYR2dwIqdTeVZscAi4iIiPRC+41GDSfxZjgzJSIiIjIQXMEiIiIivdD+swgNZ12IARYRERHphRISKKFNDRZ3ciciIiJS05ZWsAxnpkREREQGgitYREREpBfabzRqOOtCDLCIiIhIL5RCAqU2+2Bp0VffDCcUJCIiIjIQXMEiIiIivVBqmSI0pI1GGWARERGRXiiFFEot7gTUpq++Gc5MiYiIiAwEV7CIiIhILxSQQKHFZqHa9NU3BlhERESkF0wREhEREVGTcQWLiIiI9EIB7dJ8Ct1NpdkxwCIiIiK9aEspQgZYREREpBf8sGciIiIiajKuYBEREZFeCEig1KIGS3CbBiIiIiJ1TBESERERUZNxBYuIiIj0QikkUIqmp/m06atvDLCIiIhILxSQQqFF8kybvvpmODMlIiIiMhBcwSIiIiK9YIqQiIiISMeUkEKpRfJMm776ZjgzJSIiIjIQXMEiIiIivVAICRRapPm06atvDLCIiIhIL1iDRURERKRjQkih1GI3dsGd3ImIiIjaLq5gERERkV4oIIFCiw9s1qavvnEFi4iIiPRCKf6qw2ra0bRxly5dCg8PD8hkMgQHB2Pfvn0Ntk1LS4NEIlE7ZDKZxmMywCIiIqJWKz09HQkJCUhKSsKBAwfg5+eHsLAwXLx4scE+crkcRUVFquPs2bMaj8sAi8iADBl1GR//ehTfnDqM97acgLf/rZaeEtG/+jrVHtF9umFw556If/I+HDtocdf2ZTeM8MFUFzzn3x2DPXrixQd9sC/TWq3N5SITvBPnhhHd78cQz554+RFvHM8xb86XQTqg/LPIXZtDUwsXLsTYsWMRGxuLbt26Yfny5bCwsMCaNWsa7CORSODo6Kg6HBwcNB6XARapSUtLg62tbUtPg+ox4KlreCnpAtYtdMT4MC+cOirD7PWnYNO+qqWnRtSgXV/ZYuV0Z0QlFGPpt3nw7HYbbz3vieuX6y8BrqqUYOqzXVByzhRvrzyD1XuO4bV5hWjv+Nf3+c3rRkiIuA9GxgKzPj2FVbuO4aXEC7CyUejrZVETKSHR+gCA0tJStaOioqLe8SorK5GdnY3Q0FDVOalUitDQUGRlZTU4z7KyMri7u8PV1RURERH4448/NH6tLRpgjRo1ChKJBHPnzlU7v3nzZkgkzVvIdubMGbX8qrW1Nbp3747x48fjxIkTzTo2UVMMf+kyMtbb4bt0OxSckGHJ5E6ouC1B2HNXW3pqRA3atLIDwp+/grBnr8LdqwLx75yDmbkS3/7Prt72326ww83rRkhacxrd+5TD0bUSPUPK0aX7HVWbz5Z2hL1zJSYtLoRPwC04ulUi8OGbcPao1NfLohbm6uoKGxsb1ZGSklJvu8uXL0OhUNRZgXJwcEBxcXG9fby9vbFmzRp89dVX+PTTT6FUKvHAAw/g3LlzGs2xxVewZDIZ3nnnHVy7dq1Fxt+5cyeKioqQk5ODOXPmIDc3F35+fsjMzGz2sauquPJAjWNsosR9PW/hwJ6/0iRCSHBwjzW6BTJNSPemqkoJThy2QK/+ZapzUikQ0L8MR7Mt6+3zy3c28A0sxwf/7YTInt3x0kBv/G9JRygU6m28/G5h1kseGNmjO8YN8sK2dfUHbHRvqd3JXZsDAAoLC3Hjxg3VMXXqVJ3NMSQkBNHR0fD398eAAQOwadMmdOjQAStWrNDoOi0eYIWGhsLR0bHB6BMAvvjiC3Tv3h1mZmbw8PDAggUL1J738PDAnDlz8OKLL8La2hpubm5YuXJlo8Zv3749HB0d4enpiYiICOzcuRPBwcEYPXo0FH/7if7qq6/Qq1cvyGQyeHp6Yvr06aiurlY9L5FIsGzZMjz++OMwNzeHp6cnNm7cqHq+dsUsPT0dAwYMgEwmw7p16wAAq1evhq+vL2QyGXx8fPDhhx+q+lVWViIuLg5OTk6QyWRwd3dXvVdCCCQnJ8PNzQ1mZmZwdnZGfHy8qm9FRQUmTZoEFxcXWFpaIjg4GLt27VJ7/WlpaXBzc4OFhQWGDRuGK1euNOp9I/2S2ylgZAxcv6SeVrl22RjtOlQ30IuoZZVeNYJSIYFtB/U/JtvZV+HapfpThEVnTbFnqy2UCglmfXoKz79Wgi9WdMT/Fv+1AlFUYIota+3h3LkCc9afwuCYK1g2rRN2fNauWV8PaU9XNVhyuVztMDMzq3c8e3t7GBkZoaSkRO18SUkJHB0dGzVnExMTBAQE4OTJkxq91hYPsIyMjDBnzhy8//779S6/ZWdnY+TIkXj22Wdx5MgRJCcnY9q0aUhLS1Nrt2DBAgQFBeHgwYMYN24cXnnlFeTl5Wk8H6lUigkTJuDs2bPIzs4GAOzZswfR0dGYMGECjh49ihUrViAtLQ2zZ89W6ztt2jQ8/fTTyMnJQVRUFJ599lnk5uaqtZkyZQomTJiA3NxchIWFYd26dUhMTMTs2bORm5uLOXPmYNq0afj4448BAEuWLMHXX3+Nzz77DHl5eVi3bh08PDwA1ASeixYtwooVK3DixAls3rwZPXr0UI0VFxeHrKwsbNiwAYcPH8YzzzyD8PBwVQr0119/xejRoxEXF4dDhw5h4MCBmDVr1r++RxUVFXXy30REuiAEYNu+GhPmFeK+nrfxcMR1PBdfgq2f2P/VRgl0vf82XpxahK49buOJF67g8eevqLUhAgBTU1MEBgaqZaWUSiUyMzMREhLSqGsoFAocOXIETk5OGo19T2w0OmzYMPj7+yMpKQkfffSR2nMLFy7Eo48+imnTpgEAvLy8cPToUcybNw+jRo1StXviiScwbtw4AMDkyZOxaNEi/PDDD/D29tZ4Pj4+PgBqVp369OmD6dOnY8qUKYiJiQEAeHp6YubMmXjzzTeRlJSk6vfMM89gzJgxAICZM2dix44deP/999VWpF577TUMHz5c9TgpKQkLFixQnevcubMqiIuJiUFBQQHuu+8+PPjgg5BIJHB3d1f1LSgogKOjI0JDQ2FiYgI3Nzf06dNH9VxqaioKCgrg7OwMAJg0aRIyMjKQmpqKOXPm4L333kN4eDjefPNN1Xv7888/IyMj467vT0pKCqZPn67x+0pNV3rVCIpqwPYfq1Xt7KsbXAkgamlyOwWkRgLXL5monb922aTBlVe7jtUwMhYwMvrrnNt9d3D1ogmqKiUwMRWw61gNd687av1c77uDvdtsdP4aSLeU0PKzCJuw0WhCQgJiYmIQFBSEPn36YPHixSgvL0dsbCwAIDo6Gi4uLqrs0IwZM9C3b1907doV169fx7x583D27FnV7/fGavEVrFrvvPMOPv744zorPrm5uejXr5/auX79+uHEiRNqKbyePXuqvq69vbJ2j4vHH38cVlZWsLKyQvfu3f91LkII1XUAICcnBzNmzFBdw8rKCmPHjkVRURFu3fqr/uWf0XBISEid1xMUFKT6ury8HPn5+Rg9erTatWfNmoX8/HwANTcCHDp0CN7e3oiPj8d3332n6v/MM8/g9u3b8PT0xNixY/Hll1+q0pZHjhyBQqGAl5eX2rV3796tunZubi6Cg4PrzPnfTJ06VS33XVhY+K99SDvVVVKcOGyBgAdvqs5JJAL+D5bhaPbdb3knaikmpgL39byFg3utVOeUSuDQXit0Cyyvt0+33uUoOmMGpfKvc+dOmcHOoQompkLVpjBfPSV0/pQZOrqwrvVeJ7S8g1A0IcCKjIzE/PnzkZiYCH9/fxw6dAgZGRmqwveCggIUFRWp2l+7dg1jx46Fr68vnnjiCZSWluLnn39Gt27dNBr3nvnT96GHHkJYWBimTp2qtjLVWCYm6n8hSSQSKP/8CV29ejVu375db7v61AZFnTt3BlBzu+b06dPVVp5qabq7q6XlX4WdZWU1hZ+rVq2qE+gY/fnnW69evXD69Gls374dO3fuxMiRIxEaGoqNGzfC1dUVeXl52LlzJ3bs2IFx48Zh3rx52L17N8rKymBkZITs7GzVtWpZWVlBG2ZmZg3mu6n5bFppj0mLC3E8xwJ5By0wbOwlyCyU+G4Di3vp3jX8pUuY/5obvPxuwTvgFr5c1QF3bknx2LM1d7++G+8Ge8cqvPjfml9wg6Mv45tUeyyb5oKIFy/j/GkzbFjigIjRl/92zYuY+JQX/rekIx4ach15By2w7dP2eG2eZnd5kf7V7siuTf+miIuLQ1xcXL3P/bM2edGiRVi0aFGTxvm7eybAAoC5c+fC399fLa3n6+uLn376Sa3dTz/9BC8vrzqBQ0NcXFwaPQelUoklS5agc+fOCAgIAFAT5OTl5aFr16537fvLL78gOjpa7XHtNerj4OAAZ2dnnDp1ClFRUQ22k8vliIyMRGRkJEaMGIHw8HBcvXoVdnZ2MDc3x5AhQzBkyBCMHz8ePj4+OHLkCAICAqBQKHDx4kX079+/3uv6+vri119/rfMa6N60++t2sGmvQPQbxWjXoRqn/jDHW1Gdcf3yv//RQNRSHo64jhtXjLF2nhOuXTKGZ/fbmL3ulCpFeOm8KaR/y6V0dKnC7PX5WJHsgv+EesPesQpDx1zCyPF/7brt7X8biR+dRmqKE9YtcoSjayX+M+M8HhneMnejE9XnngqwevTogaioKCxZskR17vXXX0fv3r0xc+ZMREZGIisrCx988IFaXZM2rly5guLiYty6dQu///47Fi9ejH379mHr1q2qAC4xMRGDBw+Gm5sbRowYAalUipycHPz+++9qReGff/45goKC8OCDD2LdunXYt29fnZqyf5o+fTri4+NhY2OD8PBwVFRUYP/+/bh27RoSEhKwcOFCODk5ISAgAFKpFJ9//jkcHR1ha2uLtLQ0KBQKBAcHw8LCAp9++inMzc3h7u6O9u3bIyoqCtHR0ViwYAECAgJw6dIlZGZmomfPnnjyyScRHx+Pfv36Yf78+YiIiMC33377r/VX1LK+TrXH16ks5CXDEvHiZUS8eLne5+Z9UffOrG5Bt/DelrvvR9h3UCn6DuINNoamqbux/72/objnZjpjxgxVag+oWT367LPPsGHDBtx///1ITEzEjBkzmpRGrE9oaCicnJzQo0cPTJkyBb6+vjh8+DAGDhyoahMWFoYtW7bgu+++Q+/evdG3b18sWrRIreAcqAmWNmzYgJ49e2Lt2rX43//+96852zFjxmD16tVITU1Fjx49MGDAAKSlpanSk9bW1nj33XcRFBSE3r1748yZM9i2bRukUilsbW2xatUq9OvXDz179sTOnTvxzTffoH379gCA1NRUREdH4/XXX4e3tzeGDh2K3377DW5ubgCAvn37YtWqVXjvvffg5+eH7777Dm+//bZO3lciIqJ/0u6DnrVLL+qbRNRWdJNWJBIJvvzySwwdOrSlp6J3paWlsLGxwcOIgLGE6Spqnb69cKilp0DULEpvKtHO6xRu3LgBuVzePGP8+Xsi4rsXYWJp2uTrVJVX4qvH1jTrXHXlnkoREhERUev1988TbGp/Q8EAi4iIiPSipe4ibAkMsHSEmVYiIiKqxQCLiIiI9IIrWEREREQ61pYCrHtumwYiIiIiQ8cVLCIiItKLtrSCxQCLiIiI9EJAu60WDOl2MgZYREREpBdtaQWLNVhEREREOsYVLCIiItKLtrSCxQCLiIiI9KItBVhMERIRERHpGFewiIiISC/a0goWAywiIiLSCyEkEFoESdr01TemCImIiIh0jCtYREREpBdKSLTaaFSbvvrGAIuIiIj0oi3VYDFFSERERKRjXMEiIiIivWhLRe4MsIiIiEgv2lKKkAEWERER6UVbWsFiDRYRERGRjnEFi4iIiPRCaJkiNKQVLAZYREREpBcCgBDa9TcUTBESERER6RhXsIiIiEgvlJBAwp3ciYiIiHSHdxESERERUZNxBYuIiIj0QikkkHCjUSIiIiLdEULLuwgN6DZCpgiJiIiIdIwrWERERKQXbanInQEWERER6QUDLCIiIiIda0tF7qzBIiIiItIxrmARERGRXrSluwgZYBEREZFe1ARY2tRg6XAyzYwpQiIiIiId4woWERER6QXvIiQiIiLSMfHnoU1/Q8EUIREREbVqS5cuhYeHB2QyGYKDg7Fv375G9duwYQMkEgmGDh2q8ZgMsIiIiEgvalOE2hyaSk9PR0JCApKSknDgwAH4+fkhLCwMFy9evGu/M2fOYNKkSejfv3+TXisDLCIiItIPoYNDQwsXLsTYsWMRGxuLbt26Yfny5bCwsMCaNWsa7KNQKBAVFYXp06fD09NT80HBAIuIiIj0RdvVqz9XsEpLS9WOioqKeoerrKxEdnY2QkNDVeekUilCQ0ORlZXV4DRnzJiBjh07YvTo0U1+qQywiIiIyKC4urrCxsZGdaSkpNTb7vLly1AoFHBwcFA77+DggOLi4nr77N27Fx999BFWrVql1Rx5FyERERHpha52ci8sLIRcLledNzMz03JmNW7evIn/+7//w6pVq2Bvb6/VtRhgERERkV7oah8suVyuFmA1xN7eHkZGRigpKVE7X1JSAkdHxzrt8/PzcebMGQwZMkR1TqlUAgCMjY2Rl5eHLl26NGquTBESERFRq2RqaorAwEBkZmaqzimVSmRmZiIkJKROex8fHxw5cgSHDh1SHU899RQGDhyIQ4cOwdXVtdFjcwWLiIiI9ONvhepN7q+hhIQExMTEICgoCH369MHixYtRXl6O2NhYAEB0dDRcXFyQkpICmUyG+++/X62/ra0tANQ5/28YYBEREZFe6KoGSxORkZG4dOkSEhMTUVxcDH9/f2RkZKgK3wsKCiCV6j6hxwCLiIiIWrW4uDjExcXV+9yuXbvu2jctLa1JYzLAIiIiIv1oQx9GyACLiIiI9EJXdxEagkYFWF9//XWjL/jUU081eTJERERErUGjAqzGfoq0RCKBQqHQZj5ERETUmhlQmk8bjQqwajfZIiIiImqqtpQi1Oq+xDt37uhqHkRERNTaCR0cBkLjAEuhUGDmzJlwcXGBlZUVTp06BQCYNm0aPvroI51PkIiIiMjQaBxgzZ49G2lpaXj33XdhamqqOn///fdj9erVOp0cERERtSYSHRyGQeMAa+3atVi5ciWioqJgZGSkOu/n54djx47pdHJERETUijBF2LDz58+ja9eudc4rlUpUVVXpZFJEREREhkzjAKtbt27Ys2dPnfMbN25EQECATiZFRERErVAbWsHSeCf3xMRExMTE4Pz581Aqldi0aRPy8vKwdu1abNmypTnmSERERK2BkNQc2vQ3EBqvYEVEROCbb77Bzp07YWlpicTEROTm5uKbb77BoEGDmmOORERERAalSZ9F2L9/f+zYsUPXcyEiIqJWTIiaQ5v+hqLJH/a8f/9+5ObmAqipywoMDNTZpIiIiKgV0raOqjUHWOfOncNzzz2Hn376Cba2tgCA69ev44EHHsCGDRvQqVMnXc+RiIiIyKBoXIM1ZswYVFVVITc3F1evXsXVq1eRm5sLpVKJMWPGNMcciYiIqDWoLXLX5jAQGq9g7d69Gz///DO8vb1V57y9vfH++++jf//+Op0cERERtR4SUXNo099QaBxgubq61ruhqEKhgLOzs04mRURERK1QG6rB0jhFOG/ePLz66qvYv3+/6tz+/fsxYcIEzJ8/X6eTIyIiIjJEjVrBateuHSSSv/Ke5eXlCA4OhrFxTffq6moYGxvjxRdfxNChQ5tlokRERGTg2tBGo40KsBYvXtzM0yAiIqJWrw2lCBsVYMXExDT3PIiIiIhajSZvNAoAd+7cQWVlpdo5uVyu1YSIiIiolWpDK1gaF7mXl5cjLi4OHTt2hKWlJdq1a6d2EBEREdVL6OAwEBoHWG+++Sa+//57LFu2DGZmZli9ejWmT58OZ2dnrF27tjnmSERERGRQNE4RfvPNN1i7di0efvhhxMbGon///ujatSvc3d2xbt06REVFNcc8iYiIyNC1obsINV7Bunr1Kjw9PQHU1FtdvXoVAPDggw/ixx9/1O3siIiIqNWo3cldm8NQaBxgeXp64vTp0wAAHx8ffPbZZwBqVrZqP/yZiIiIqC3TOMCKjY1FTk4OAGDKlClYunQpZDIZJk6ciDfeeEPnEyQiIqJWog0VuWtcgzVx4kTV16GhoTh27Biys7PRtWtX9OzZU6eTIyIiIjJEWu2DBQDu7u5wd3fXxVyIiIioFZNAuzoqwylxb2SAtWTJkkZfMD4+vsmTISIiImoNGhVgLVq0qFEXk0gkDLCIqFXy3PRyS0+BqFkob98BME0/g7WhbRoaFWDV3jVIRERE1GT8qBwiIiIiaiqti9yJiIiIGqUNrWAxwCIiIiK90HY39la9kzsRERER3R1XsIiIiEg/2lCKsEkrWHv27MELL7yAkJAQnD9/HgDwySefYO/evTqdHBEREbUibeijcjQOsL744guEhYXB3NwcBw8eREVFBQDgxo0bmDNnjs4nSERERGRoNA6wZs2aheXLl2PVqlUwMTFRne/Xrx8OHDig08kRERFR61Fb5K7NYSg0rsHKy8vDQw89VOe8jY0Nrl+/ros5ERERUWvUhnZy13gFy9HRESdPnqxzfu/evfD09NTJpIiIiKgVYg1Ww8aOHYsJEybg119/hUQiwYULF7Bu3TpMmjQJr7zySnPMkYiIiKjJli5dCg8PD8hkMgQHB2Pfvn0Ntt20aROCgoJga2sLS0tL+Pv745NPPtF4TI1ThFOmTIFSqcSjjz6KW7du4aGHHoKZmRkmTZqEV199VeMJEBERUdvQEhuNpqenIyEhAcuXL0dwcDAWL16MsLAw5OXloWPHjnXa29nZ4a233oKPjw9MTU2xZcsWxMbGomPHjggLC9NgrkI06aVWVlbi5MmTKCsrQ7du3WBlZdWUy1ArUFpaChsbGzyMCBhLTP69A5EBOvFBcEtPgahZKG/fQeGkabhx4wbkcnmzjFH7e8IzcQ6kMlmTr6O8cwenZvxXo7kGBwejd+/e+OCDD2quoVTC1dUVr776KqZMmdKoa/Tq1QtPPvkkZs6c2ei5Nnknd1NTU3Tr1g19+vRhcEVERER6U1paqnbUbhn1T5WVlcjOzkZoaKjqnFQqRWhoKLKysv51HCEEMjMzG7zB7240ThEOHDgQEknDVfzff/+9ppckIiKitkDbrRb+7Ovq6qp2OikpCcnJyXWaX758GQqFAg4ODmrnHRwccOzYsQaHuXHjBlxcXFBRUQEjIyN8+OGHGDRokEZT1TjA8vf3V3tcVVWFQ4cO4ffff0dMTIymlyMiIqK2QkcflVNYWKiWIjQzM9NqWv9kbW2NQ4cOoaysDJmZmUhISICnpycefvjhRl9D4wBr0aJF9Z5PTk5GWVmZppcjIiIi0ohcLm9UDZa9vT2MjIxQUlKidr6kpASOjo4N9pNKpejatSuAmoWl3NxcpKSkaBRgNbkG659eeOEFrFmzRleXIyIiotZGz/tgmZqaIjAwEJmZmapzSqUSmZmZCAkJafR1lEplg3VeDdF4BashWVlZkGlxZwARERG1bi2xTUNCQgJiYmIQFBSEPn36YPHixSgvL0dsbCwAIDo6Gi4uLkhJSQEApKSkICgoCF26dEFFRQW2bduGTz75BMuWLdNoXI0DrOHDh6s9FkKgqKgI+/fvx7Rp0zS9HBEREVGziYyMxKVLl5CYmIji4mL4+/sjIyNDVfheUFAAqfSvhF55eTnGjRuHc+fOwdzcHD4+Pvj0008RGRmp0bgaB1g2NjZqj6VSKby9vTFjxgw89thjml6OiIiIqFnFxcUhLi6u3ud27dql9njWrFmYNWuW1mNqFGApFArExsaiR48eaNeundaDExERURuio7sIDYFGRe5GRkZ47LHHcP369WaaDhEREbVWtTVY2hyGQuO7CO+//36cOnWqOeZCRERE1CpoHGDNmjULkyZNwpYtW1BUVFRnu3oiIiKiBulpi4aW1ugarBkzZuD111/HE088AQB46qmn1D4yRwgBiUQChUKh+1kSERGR4WtDNViNDrCmT5+O//znP/jhhx+acz5EREREBq/RAZYQNWHjgAEDmm0yRERE1Hq1xEajLUWjbRr+nhIkIiIi0ghThPXz8vL61yDr6tWrWk2IiIiIyNBpFGBNnz69zk7uRERERI3BFGEDnn32WXTs2LG55kJEREStWRtKETZ6HyzWXxERERE1jsZ3ERIRERE1SRtawWp0gKVUKptzHkRERNTKsQaLiIiISNfa0AqWxp9FSERERER3xxUsIiIi0o82tILFAIuIiIj0oi3VYDFFSERERKRjXMEiIiIi/WCKkIiIiEi3mCIkIiIioibjChYRERHpB1OERERERDrWhgIspgiJiIiIdIwrWERERKQXkj8PbfobCgZYREREpB9tKEXIAIuIiIj0gts0EBEREVGTcQWLiIiI9IMpQiIiIqJmYEBBkjaYIiQiIiLSMa5gERERkV60pSJ3BlhERESkH22oBospQiIiIiId4woWERER6QVThERERES6xhQhERERETUVV7CIiIhIL5giJCIiItK1NpQiZIBFRERE+tGGAizWYBERERHpGFewiIiISC9Yg0VERESka0wREhEREVFTcQWLiIiI9EIiBCSi6ctQ2vTVN65gERERkX4IHRxNsHTpUnh4eEAmkyE4OBj79u1rsO2qVavQv39/tGvXDu3atUNoaOhd2zeEARYRERG1Wunp6UhISEBSUhIOHDgAPz8/hIWF4eLFi/W237VrF5577jn88MMPyMrKgqurKx577DGcP39eo3EZYBEREZFe1N5FqM0BAKWlpWpHRUVFg2MuXLgQY8eORWxsLLp164bly5fDwsICa9asqbf9unXrMG7cOPj7+8PHxwerV6+GUqlEZmamRq+VARYRERHph45ShK6urrCxsVEdKSkp9Q5XWVmJ7OxshIaGqs5JpVKEhoYiKyurUVO+desWqqqqYGdnp9FLZZE7ERERGZTCwkLI5XLVYzMzs3rbXb58GQqFAg4ODmrnHRwccOzYsUaNNXnyZDg7O6sFaY3BAIuIiIj0QlcbjcrlcrUAq7nMnTsXGzZswK5duyCTyTTqywCLiIiI9EPPG43a29vDyMgIJSUlaudLSkrg6Oh4177z58/H3LlzsXPnTvTs2VPTmbIGi4iIiPRDV0XujWVqaorAwEC1AvXagvWQkJAG+7377ruYOXMmMjIyEBQU1KTXyhUsIiIiarUSEhIQExODoKAg9OnTB4sXL0Z5eTliY2MBANHR0XBxcVEVyr/zzjtITEzE+vXr4eHhgeLiYgCAlZUVrKysGj0uAywiIiLSjxb4LMLIyEhcunQJiYmJKC4uhr+/PzIyMlSF7wUFBZBK/0roLVu2DJWVlRgxYoTadZKSkpCcnNzocRlgERERkd5oU+TeVHFxcYiLi6v3uV27dqk9PnPmjE7GZA0WERERkY5xBYuIiIj0Q4iaQ5v+BoIBFhEREemFrvbBMgRMERIRERHpGFewiIiISD9a4C7ClsIAi4iIiPRCoqw5tOlvKJgiJCIiItIxrmARGZAhoy5jxCsXYdehGqeOmuPDt12Qd8iipadFdFc2u4vRLrMIRqVVqHSxwMVnPFDhUf+O2JaHrsLu2wswuXwHEoVAVQcZrj3qiJt9OtTbvuP/TsPmp4u49LQbrg90as6XQbrQhlKEXMEiNR4eHli8eHFLT4PqMeCpa3gp6QLWLXTE+DAvnDoqw+z1p2DTvqqlp0bUIKvsK7D/sgBXH++Ewsn3o8LFAi5Lj8HoZv3ft0oLY1wNd0bh691RMLUHSvt2gMOnp2Bx9HqdtpY5VyE7U4ZqG5NmfhWkK/r+LMKW1KYDrFGjRkEikUAikcDExAQODg4YNGgQ1qxZA6XSgBK91CYMf+kyMtbb4bt0OxSckGHJ5E6ouC1B2HNXW3pqRA1q930RSh/oiNKQDqh0ssDFZztDmEohz7pUb/vbXnKU+9mhytEcVR1kuD7QERXOFpCduqnWzuh6JTp8fgbFo7pAGEn08VJIF2r3wdLmMBBtOsACgPDwcBQVFeHMmTPYvn07Bg4ciAkTJmDw4MGorq5utnErKyub7drU+hibKHFfz1s4sMdadU4ICQ7usUa3wFstODOiu6hWwqywHLe85X+dk0pwy9sGstM3G+5XSwiY592A6cU7uNPlb9dQCjiuzcf1R51R6cQUOd2b2nyAZWZmBkdHR7i4uKBXr17473//i6+++grbt29HWloaAOD69esYM2YMOnToALlcjkceeQQ5OTmqayQnJ8Pf3x8rVqyAq6srLCwsMHLkSNy4cUPVZtSoURg6dChmz54NZ2dneHt7AwAKCwsxcuRI2Nraws7ODhEREWqfg7Rr1y706dMHlpaWsLW1Rb9+/XD27FkAQE5ODgYOHAhra2vI5XIEBgZi//79qr579+5F//79YW5uDldXV8THx6O8vFz1/MWLFzFkyBCYm5ujc+fOWLduXaPes4qKCpSWlqod1LzkdgoYGQPXL6mXTV67bIx2HZrvDwEibRiVVUOiBBTW6im8arkJjEsbTm1Lb1ejS8Jv6DrhNzgvy8OlZ9xxy9dG9Xy7HRcgpMD1hx2abe7UPJgibOMeeeQR+Pn5YdOmTQCAZ555BhcvXsT27duRnZ2NXr164dFHH8XVq3+lZk6ePInPPvsM33zzDTIyMnDw4EGMGzdO7bqZmZnIy8vDjh07sGXLFlRVVSEsLAzW1tbYs2cPfvrpJ1hZWSE8PByVlZWorq7G0KFDMWDAABw+fBhZWVl46aWXIJHULIdHRUWhU6dO+O2335CdnY0pU6bAxKTmH7L8/HyEh4fj6aefxuHDh5Geno69e/eqfdjlqFGjUFhYiB9++AEbN27Ehx9+iIsXL/7r+5OSkgIbGxvV4erqqvV7TkRUS2lmhIKpPVDwZndcGeIK+00FMD9e84ecWUE5bHeVoOSFLoCEqUGDI3RwGAjeRdgAHx8fHD58GHv37sW+fftw8eJFmJmZAQDmz5+PzZs3Y+PGjXjppZcAAHfu3MHatWvh4uICAHj//ffx5JNPYsGCBXB0dAQAWFpaYvXq1TA1NQUAfPrpp1AqlVi9erUqaEpNTYWtrS127dqFoKAg3LhxA4MHD0aXLl0AAL6+vqo5FhQU4I033oCPjw8A4L777lM9l5KSgqioKLz22muq55YsWYIBAwZg2bJlKCgowPbt27Fv3z707t0bAPDRRx+pXb8hU6dORUJCgupxaWkpg6xmVnrVCIpqwPYfq1Xt7Ktx7RJ/jOnepLAyhpCiTkG7cWkVquV3KUyXSlDVQQYAqOxkCdPi22j33QXc9pLDPL8URmVV6Jx4UNVcogTsNxXA9odinJkR0CyvhUhT/Je5AUIISCQS5OTkoKysDO3bt1d7/vbt28jPz1c9dnNzUwVXABASEgKlUom8vDxVgNWjRw9VcAXUpPhOnjwJa+u/6mqAmmAtPz8fjz32GEaNGoWwsDAMGjQIoaGhGDlyJJycam5FTkhIwJgxY/DJJ58gNDQUzzzzjCoQy8nJweHDh9XSfkIIKJVKnD59GsePH4exsTECAwNVz/v4+MDW1vZf3xszMzNVsEn6UV0lxYnDFgh48CayMmpSJRKJgP+DZfg6rf2/9CZqIcZSVLhawiKvFOV+djXnlALmx2/gxkOOjb+OACTVNTcelfa2xy1vG7WnXZYeQ2kfe5T2rX8rB7p3tKXPImSA1YDc3Fx07twZZWVlcHJywq5du+q0aUww8neWlpZqj8vKyhAYGFhv7VOHDjX/UKSmpiI+Ph4ZGRlIT0/H22+/jR07dqBv375ITk7G888/j61bt2L79u1ISkrChg0bMGzYMJSVleHll19GfHx8nWu7ubnh+PHjGs2dWt6mlfaYtLgQx3MskHfQAsPGXoLMQonvNti19NSIGnTtESc4fJKPO26WuONhhXY/FENaoVQFQw5r81FtY4IrEW4AgHbfnkeFmxUqO5hBUi1g+cd1yPddxsVnPQAASisTVFqpr34JIwkUchNUOZjr9bVRE2h7J6AB3UXIAKse33//PY4cOYKJEyeiU6dOKC4uhrGxMTw8PBrsU1BQgAsXLsDZ2RkA8Msvv0AqlaqK2evTq1cvpKeno2PHjpDL5Q22CwgIQEBAAKZOnYqQkBCsX78effv2BQB4eXnBy8sLEydOxHPPPYfU1FQMGzYMvXr1wtGjR9G1a9d6r+nj44Pq6mpkZ2erUoR5eXm4fv36v7w71FJ2f90ONu0ViH6jGO06VOPUH+Z4K6ozrl/mHkB07yoLbA+jsiq033oORjdrNho9P94Hij9ThMZXK4C/lVJJK5Xo8NlpGF+vhDCRotLBHMUxXVAWyJVaMixtPsCqqKhAcXExFAoFSkpKkJGRgZSUFAwePBjR0dGQSqUICQnB0KFD8e6778LLywsXLlzA1q1bMWzYMAQFBQEAZDIZYmJiMH/+fJSWliI+Ph4jR45UpQfrExUVhXnz5iEiIgIzZsxAp06dcPbsWWzatAlvvvkmqqqqsHLlSjz11FNwdnZGXl4eTpw4gejoaNy+fRtvvPEGRowYgc6dO+PcuXP47bff8PTTTwMAJk+ejL59+yIuLg5jxoyBpaUljh49ih07duCDDz6At7c3wsPD8fLLL2PZsmUwNjbGa6+9BnNz/gV4L/s61R5fp9q39DSINHJjgCNuDKj/38Lzr3VTe3xliCuuDNGsppN1V4aDKcI2JCMjA05OTjA2Nka7du3g5+eHJUuWICYmBlJpzU2W27Ztw1tvvYXY2FhcunQJjo6OeOihh+Dg8Nctwl27dsXw4cPxxBNP4OrVqxg8eDA+/PDDu45tYWGBH3/8EZMnT8bw4cNx8+ZNuLi44NFHH4VcLsft27dx7NgxfPzxx7hy5QqcnJwwfvx4vPzyy6iursaVK1cQHR2NkpIS2NvbY/jw4Zg+fToAoGfPnti9ezfeeust9O/fH0IIdOnSBZGRkarxU1NTMWbMGAwYMAAODg6YNWsWpk2b1gzvMhEREdrUR+VIhDCghOY9Kjk5GZs3b8ahQ4daeiotorS0FDY2NngYETCWMF1FrdOJD4JbegpEzUJ5+w4KJ03DjRs37lquoo3a3xMh4TNgbCJr8nWqq+4gKyOxWeeqK21+BYuIiIj0gylCIiIiIl1TippDm/4Ggju560BycnKbTQ8SERE1WhvayZ0BFhEREZGOMUVIREREeiGBljVYOptJ82OARURERPrRhnZyZ4qQiIiISMe4gkVERER6wW0aiIiIiHStDe3kzhQhERERkY5xBYuIiIj0QiIEJFoUqmvTV98YYBEREZF+KP88tOlvIJgiJCIiItIxrmARERGRXjBFSERERKRrbeguQgZYREREpB/cyZ2IiIiImoorWERERKQX3MmdiIiISNeYIiQiIiKipuIKFhEREemFRFlzaNPfUDDAIiIiIv1gipCIiIiImoorWERERKQf3GiUiIiISLfa0kflMEVIRERErdrSpUvh4eEBmUyG4OBg7Nu3r8G2f/zxB55++ml4eHhAIpFg8eLFTRqTARYRERHpR22RuzaHhtLT05GQkICkpCQcOHAAfn5+CAsLw8WLF+ttf+vWLXh6emLu3LlwdHRs8ktlgEVERET6IQAotTj+jK9KS0vVjoqKigaHXLhwIcaOHYvY2Fh069YNy5cvh4WFBdasWVNv+969e2PevHl49tlnYWZm1uSXygCLiIiI9KK2BkubAwBcXV1hY2OjOlJSUuodr7KyEtnZ2QgNDVWdk0qlCA0NRVZWVrO+Vha5ExERkUEpLCyEXC5XPW5openy5ctQKBRwcHBQO+/g4IBjx4416xwZYBEREZF+CGi50WjNf+RyuVqAdS9igEVERET6oeed3O3t7WFkZISSkhK18yUlJVoVsDcGa7CIiIioVTI1NUVgYCAyMzNV55RKJTIzMxESEtKsY3MFi4iIiPRDCUCiZX8NJSQkICYmBkFBQejTpw8WL16M8vJyxMbGAgCio6Ph4uKiKpSvrKzE0aNHVV+fP38ehw4dgpWVFbp27drocRlgERERkV60xE7ukZGRuHTpEhITE1FcXAx/f39kZGSoCt8LCgoglf6V0Ltw4QICAgJUj+fPn4/58+djwIAB2LVrV6PHZYBFRERErVpcXBzi4uLqfe6fQZOHhweEDj6ShwEWERER6Yeei9xbEgMsIiIi0o82FGDxLkIiIiIiHeMKFhEREelHG1rBYoBFRERE+tEC2zS0FAZYREREpBctsU1DS2ENFhEREZGOcQWLiIiI9IM1WEREREQ6phSARIsgSWk4ARZThEREREQ6xhUsIiIi0g+mCImIiIh0TcsAC4YTYDFFSERERKRjXMEiIiIi/WCKkIiIiEjHlAJapfl4FyERERFR28UVLCIiItIPoaw5tOlvIBhgERERkX6wBouIiIhIx1iDRURERERNxRUsIiIi0g+mCImIiIh0TEDLAEtnM2l2TBESERER6RhXsIiIiEg/mCIkIiIi0jGlEoAWe1kpDWcfLKYIiYiIiHSMK1hERESkH0wREhEREelYGwqwmCIkIiIi0jGuYBEREZF+tKGPymGARURERHohhBJCNP1OQG366hsDLCIiItIPIbRbhWINFhEREVHbxRUsIiIi0g+hZQ2WAa1gMcAiIiIi/VAqAYkWdVQGVIPFFCERERGRjnEFi4iIiPSDKUIiIiIi3RJKJYQWKUJD2qaBKUIiIiIiHeMKFhEREekHU4REREREOqYUgKRtBFhMERIRERHpGFewiIiISD+EAKDNPliGs4LFAIuIiIj0QigFhBYpQsEAi4iIiOgfhBLarWBxmwYiIiKie8LSpUvh4eEBmUyG4OBg7Nu3767tP//8c/j4+EAmk6FHjx7Ytm2bxmMywCIiIiK9EEqh9aGp9PR0JCQkICkpCQcOHICfnx/CwsJw8eLFetv//PPPeO655zB69GgcPHgQQ4cOxdChQ/H7779rNC4DLCIiItIPodT+0NDChQsxduxYxMbGolu3bli+fDksLCywZs2aetu/9957CA8PxxtvvAFfX1/MnDkTvXr1wgcffKDRuKzBIq3VFh1Wo0qr/eOI7mXK23daegpEzUJ5p+Z7Wx8F5Nr+nqhGFQCgtLRU7byZmRnMzMzqtK+srER2djamTp2qOieVShEaGoqsrKx6x8jKykJCQoLaubCwMGzevFmjuTLAIq3dvHkTALAXmueoiQzGpK9aegZEzermzZuwsbFplmubmprC0dERe4u1/z1hZWUFV1dXtXNJSUlITk6u0/by5ctQKBRwcHBQO+/g4IBjx47Ve/3i4uJ62xcXF2s0TwZYpDVnZ2cUFhbC2toaEomkpafT6pWWlsLV1RWFhYWQy+UtPR0ineP3uH4JIXDz5k04Ozs32xgymQynT59GZWWl1tcSQtT5XVPf6lVLY4BFWpNKpejUqVNLT6PNkcvl/OVDrRq/x/WnuVau/k4mk0EmkzX7OH9nb28PIyMjlJSUqJ0vKSmBo6NjvX0cHR01at8QFrkTERFRq2RqaorAwEBkZmaqzimVSmRmZiIkJKTePiEhIWrtAWDHjh0Ntm8IV7CIiIio1UpISEBMTAyCgoLQp08fLF68GOXl5YiNjQUAREdHw8XFBSkpKQCACRMmYMCAAViwYAGefPJJbNiwAfv378fKlSs1GpcBFpGBMTMzQ1JS0j1Zc0CkC/weJ12KjIzEpUuXkJiYiOLiYvj7+yMjI0NVyF5QUACp9K+E3gMPPID169fj7bffxn//+1/cd9992Lx5M+6//36NxpUIQ/pgHyIiIiIDwBosIiIiIh1jgEVERESkYwywiIiIiHSMARYRtYi0tDTY2tq29DSIGuTh4YHFixe39DTIQDHAojZh1KhRkEgkmDt3rtr5zZs3N/vu82fOnIFEIlEd1tbW6N69O8aPH48TJ04069hEjVX7MyKRSGBiYgIHBwcMGjQIa9asgVKp+QfsErV1DLCozZDJZHjnnXdw7dq1Fhl/586dKCoqQk5ODubMmYPc3Fz4+fnV2dCuOVRVVTX7GGT4wsPDUVRUhDNnzmD79u0YOHAgJkyYgMGDB6O6urrZxtXFx6cQ3WsYYFGbERoaCkdHR9VmcvX54osv0L17d5iZmcHDwwMLFixQe97DwwNz5szBiy++CGtra7i5uTV687n27dvD0dERnp6eiIiIwM6dOxEcHIzRo0dDoVCo2n311Vfo1asXZDIZPD09MX36dLVfbhKJBMuWLcPjjz8Oc3NzeHp6YuPGjarna1fM0tPTMWDAAMhkMqxbtw4AsHr1avj6+kImk8HHxwcffvihql9lZSXi4uLg5OQEmUwGd3d31XslhEBycjLc3NxgZmYGZ2dnxMfHq/pWVFRg0qRJcHFxgaWlJYKDg7Fr1y6115+WlgY3NzdYWFhg2LBhuHLlSqPeN9IfMzMzODo6wsXFBb169cJ///tffPXVV9i+fTvS0tIAANevX8eYMWPQoUMHyOVyPPLII8jJyVFdIzk5Gf7+/lixYgVcXV1hYWGBkSNH4saNG6o2o0aNwtChQzF79mw4OzvD29sbAFBYWIiRI0fC1tYWdnZ2iIiIwJkzZ1T9du3ahT59+sDS0hK2trbo168fzp49CwDIycnBwIEDYW1tDblcjsDAQOzfv1/Vd+/evejfvz/Mzc3h6uqK+Ph4lJeXq56/ePEihgwZAnNzc3Tu3Fn1M0PUZIKoDYiJiRERERFi06ZNQiaTicLCQiGEEF9++aWo/THYv3+/kEqlYsaMGSIvL0+kpqYKc3NzkZqaqrqOu7u7sLOzE0uXLhUnTpwQKSkpQiqVimPHjjU49unTpwUAcfDgwTrP1Y7/66+/CiGE+PHHH4VcLhdpaWkiPz9ffPfdd8LDw0MkJyer+gAQ7du3F6tWrRJ5eXni7bffFkZGRuLo0aNq43l4eIgvvvhCnDp1Sly4cEF8+umnwsnJSXXuiy++EHZ2diItLU0IIcS8efOEq6ur+PHHH8WZM2fEnj17xPr164UQQnz++edCLpeLbdu2ibNnz4pff/1VrFy5UjWnMWPGiAceeED8+OOP4uTJk2LevHnCzMxMHD9+XAghxC+//CKkUql45513RF5ennjvvfeEra2tsLGx0fD/JDWX2p+R+vj5+YnHH39cCCFEaGioGDJkiPjtt9/E8ePHxeuvvy7at28vrly5IoQQIikpSVhaWopHHnlEHDx4UOzevVt07dpVPP/882pjWVlZif/7v/8Tv//+u/j9999FZWWl8PX1FS+++KI4fPiwOHr0qHj++eeFt7e3qKioEFVVVcLGxkZMmjRJnDx5Uhw9elSkpaWJs2fPCiGE6N69u3jhhRdEbm6uOH78uPjss8/EoUOHhBBCnDx5UlhaWopFixaJ48ePi59++kkEBASIUaNGqeb0+OOPCz8/P5GVlSX2798vHnjgAWFubi4WLVrUDO82tQUMsKhN+Psvj759+4oXX3xRCKEeYD3//PNi0KBBav3eeOMN0a1bN9Vjd3d38cILL6geK5VK0bFjR7Fs2bIGx75bgJWbmysAiPT0dCGEEI8++qiYM2eOWptPPvlEODk5qR4DEP/5z3/U2gQHB4tXXnlFbbzFixertenSpYsqYKo1c+ZMERISIoQQ4tVXXxWPPPKIUCqVdea5YMEC4eXlJSorK+s8d/bsWWFkZCTOnz+vdv7RRx8VU6dOFUII8dxzz4knnnhC7fnIyEgGWPeQuwVYkZGRwtfXV+zZs0fI5XJx584dtee7dOkiVqxYIYSoCbCMjIzEuXPnVM9v375dSKVSUVRUpBrLwcFBVFRUqNp88sknwtvbW+37r6KiQpibm4tvv/1WXLlyRQAQu3btqneO1tbWqj8W/mn06NHipZdeUju3Z88eIZVKxe3bt0VeXp4AIPbt26d6vvZnkwEWNRVThNTmvPPOO/j444+Rm5urdj43Nxf9+vVTO9evXz+cOHFCLYXXs2dP1dcSiQSOjo64ePEiAODxxx+HlZUVrKys0L1793+di/jzgxRqC+1zcnIwY8YM1TWsrKwwduxYFBUV4datW6p+//zQ0ZCQkDqvJygoSPV1eXk58vPzMXr0aLVrz5o1C/n5+QBq0jaHDh2Ct7c34uPj8d1336n6P/PMM7h9+zY8PT0xduxYfPnll6q05ZEjR6BQKODl5aV27d27d6uunZubi+Dg4DpzJsMghIBEIkFOTg7KysrQvn17tf/Xp0+fVv2/BgA3Nze4uLioHoeEhECpVCIvL091rkePHjA1NVU9zsnJwcmTJ2Ftba26rp2dHe7cuYP8/HzY2dlh1KhRCAsLw5AhQ/Dee++hqKhI1T8hIQFjxoxBaGgo5s6dqzafnJwcpKWlqc05LCwMSqUSp0+fRm5uLoyNjREYGKjq4+Pjw7tcSSv8LEJqcx566CGEhYVh6tSpGDVqlMb9TUxM1B5LJBLVXVarV6/G7du3621Xn9qgqHPnzgCAsrIyTJ8+HcOHD6/TViaTaTRPS0tL1ddlZWUAgFWrVtUJdIyMjAAAvXr1wunTp7F9+3bs3LkTI0eORGhoKDZu3AhXV1fk5eVh586d2LFjB8aNG4d58+Zh9+7dKCsrg5GREbKzs1XXqmVlZaXRnOnelJubi86dO6OsrAxOTk516usAaByM/P37E6j5Hg0MDKy39qlDhw4AgNTUVMTHxyMjIwPp6el4++23sWPHDvTt2xfJycl4/vnnsXXrVmzfvh1JSUnYsGEDhg0bhrKyMrz88stqdYO13NzccPz4cY3mTtQYDLCoTZo7dy78/f1VxbUA4Ovri59++kmt3U8//QQvL686gUND/v5X+79RKpVYsmQJOnfujICAAAA1QU5eXh66du16176//PILoqOj1R7XXqM+Dg4OcHZ2xqlTpxAVFdVgO7lcjsjISERGRmLEiBEIDw/H1atXYWdnB3NzcwwZMgRDhgzB+PHj4ePjgyNHjiAgIAAKhQIXL15E//79672ur68vfv311zqvge5933//PY4cOYKJEyeiU6dOKC4uhrGxMTw8PBrsU1BQgAsXLsDZ2RlAzf9rqVSq9vP2T7169UJ6ejo6duwIuVzeYLuAgAAEBARg6tSpCAkJwfr169G3b18AgJeXF7y8vDBx4kQ899xzSE1NxbBhw9CrVy8cPXq0wZ8rHx8fVFdXIzs7G7179wYA5OXl4fr16//y7hA1jAEWtUk9evRAVFQUlixZojr3+uuvo3fv3pg5cyYiIyORlZWFDz74QO1OO21cuXIFxcXFuHXrFn7//XcsXrwY+/btw9atW1UBXGJiIgYPHgw3NzeMGDECUqkUOTk5+P333zFr1izVtT7//HMEBQXhwQcfxLp167Bv3z589NFHdx1/+vTpiI+Ph42NDcLDw1FRUYH9+/fj2rVrSEhIwMKFC+Hk5ISAgABIpVJ8/vnncHR0hK2tLdLS0qBQKBAcHAwLCwt8+umnMDc3h7u7O9q3b4+oqChER0djwYIFCAgIwKVLl5CZmYmePXviySefRHx8PPr164f58+cjIiIC3377LTIyMnTyvpLuVFRUoLi4GAqFAiUlJcjIyEBKSgoGDx6M6OhoSKVShISEYOjQoXj33Xfh5eWFCxcuYOvWrRg2bJgqLS2TyRATE4P58+ejtLQU8fHxGDlyJBwdHRscOyoqCvPmzUNERARmzJiBTp064ezZs9i0aRPefPNNVFVVYeXKlXjqqafg7OyMvLw8nDhxAtHR0bh9+zbeeOMNjBgxAp07d8a5c+fw22+/4emnnwYATJ48GX379kVcXBzGjBkDS0tLHD16FDt27MAHH3wAb29vhIeH4+WXX8ayZctgbGyM1157Debm5np536mVaukiMCJ9qK+A9/Tp08LU1FT8/cdg48aNolu3bsLExES4ubmJefPmqfVxd3evU/Tq5+cnkpKSGhy7tui89rCwsBC+vr5i3Lhx4sSJE3XaZ2RkqO5gksvlok+fPmp37AEQS5cuFYMGDRJmZmbCw8NDVST/9/HqK6pft26d8Pf3F6ampqJdu3bioYceEps2bRJCCLFy5Urh7+8vLC0thVwuF48++qg4cOCAEKLmZoDg4GAhl8uFpaWl6Nu3r9i5c6fqupWVlSIxMVF4eHgIExMT4eTkJIYNGyYOHz6savPRRx+JTp06CXNzczFkyBAxf/58FrnfQ2JiYlTfo8bGxqJDhw4iNDRUrFmzRigUClW70tJS8eqrrwpnZ2dhYmIiXF1dRVRUlCgoKBBC1BS5+/n5iQ8//FA4OzsLmUwmRowYIa5evao2Vn0F9UVFRSI6OlrY29sLMzMz4enpKcaOHStu3LghiouLxdChQ4WTk5MwNTUV7u7uIjExUSgUClFRUSGeffZZ4erqKkxNTYWzs7OIi4sTt2/fVl173759YtCgQcLKykpYWlqKnj17itmzZ6uN/eSTTwozMzPh5uYm1q5dW+/PO1FjSYT4s8qWiAyCRCLBl19+iaFDh7b0VIjqSE5OxubNm3Ho0KGWngpRi+JdhEREREQ6xgCLiIiISMeYIiQiIiLSMa5gEREREekYAywiIiIiHWOARURERKRjDLCIiIiIdIwBFhEREZGOMcAiolZh1KhRapuvPvzww3jttdf0Po9du3ZBIpHc9XPsJBIJNm/e3OhrJicnw9/fX6t5nTlzBhKJhBuAEukJAywiajajRo2CRCKBRCKBqakpunbtihkzZqC6urrZx960aRNmzpzZqLaNCYqIiDTBD3smomYVHh6O1NRUVFRUYNu2bRg/fjxMTEwwderUOm0rKythamqqk3Ht7Ox0ch0ioqbgChYRNSszMzM4OjrC3d0dr7zyCkJDQ/H1118D+CutN3v2bDg7O8Pb2xsAUFhYiJEjR8LW1hZ2dnaIiIjAmTNnVNdUKBRISEiAra0t2rdvjzfffBP/3DP5nynCiooKTJ48Ga6urjAzM0PXrl3x0Ucf4cyZMxg4cCAAoF27dpBIJBg1ahQAQKlUIiUlBZ07d4a5uTn8/PywceNGtXG2bdsGLy8vmJubY+DAgWrzbKzJkyfDy8sLFhYW8PT0xLRp01BVVVWn3YoVK+Dq6goLCwuMHDkSN27cUHt+9erV8PX1hUwmg4+PDz788EON50JEusEAi4j0ytzcHJWVlarHmZmZyMvLw44dO7BlyxZUVVUhLCwM1tbW2LNnD3766SdYWVkhPDxc1W/BggVIS0vDmjVrsHfvXly9ehVffvnlXceNjo7G//73PyxZsgS5ublYsWIFrKys4Orqii+++AIAkJeXh6KiIrz33nsAgJSUFKxduxbLly/HH3/8gYkTJ+KFF17A7t27AdQEgsOHD8eQIUNw6NAhjBkzBlOmTNH4PbG2tkZaWhqOHj2K9957D6tWrcKiRYvU2pw8eRKfffYZvvnmG2RkZODgwYMYN26c6vl169YhMTERs2fPRm5uLubMmYNp06bh448/1ng+RKQDgoiomcTExIiIiAghhBBKpVLs2LFDmJmZiUmTJqmed3BwEBUVFao+n3zyifD29hZKpVJ1rqKiQpibm4tvv/1WCCGEk5OTePfdd1XPV1VViU6dOqnGEkKIAQMGiAkTJgghhMjLyxMAxI4dO+qd5w8//CAAiGvXrqnO3blzR1hYWIiff/5Zre3o0aPFc889J4QQYurUqaJbt25qz0+ePLnOtf4JgPjyyy8bfH7evHkiMDBQ9TgpKUkYGRmJc+fOqc5t375dSKVSUVRUJIQQokuXLmL9+vVq15k5c6YICQkRQghx+vRpAUAcPHiwwXGJSHdYg0VEzWrLli2wsrJCVVUVlEolnn/+eSQnJ6ue79Gjh1rdVU5ODk6ePAlra2u169y5cwf5+fm4ceMGioqKEBwcrHrO2NgYQUFBddKEtQ4dOgQjIyMMGDCg0fM+efIkbt26hUGDBqmdr6ysREBAAAAgNzdXbR4AEBIS0ugxaqWnp2PJkiXIz89HWVkZqqurIZfL1dq4ubnBxcVFbRylUom8vDxYW1sjPz8fo0ePxtixY1VtqqurYWNjo/F8iEh7DLCIqFkNHDgQy5Ytg6mpKZydnWFsrP7PjqWlpdrjsrIyBAYGYt26dXWu1aFDhybNwdzcXOM+ZWVlAICtW7eqBTZATV2ZrmRlZSEqKgrTp09HWFgYbGxssGHDBixYsEDjua5atapOwGdkZKSzuRJR4zHAIqJmZWlpia5duza6fa9evZCeno6OHTvWWcWp5eTkhF9//RUPPfQQgJqVmuzsbPTq1ave9j169IBSqcTu3bsRGhpa5/naFTSFQqE6161bN5iZmaGgoKDBlS9fX19VwX6tX3755d9f5N/8/PPPcHd3x1tvvaU6d/bs2TrtCgoKcOHCBTg7O6vGkUql8Pb2hoODA5ydnXHq1ClERUVpND4RNQ8WuRPRPSUqKgr29vaIiIjAnj17cPr0aezatQvx8fE4d+4cAGDChAmYO3cuNm/ejGPHjmHcuHF33cPKw8MDMTExePHFF7F582bVNT/77DMAgLu7OyQSCbZs2YJLly6hrKwM1tbWmDRpEiZOnIiPP/4Y+fn5OHDgAN5//31V4fh//vMfnDhxAm+88Qby8vKwfv16pKWlafR677vvPhQUFGDDhg3Iz8/HkiVL6i3Yl8lkiImJQU5ODvbs2YP4+HiMHDkSjo6OAIDp06cjJSUFS5YswfHjx3HkyBGkpqZi4cKFGs2HiHSDARYR3VMsLCzw448/ws3NDcOHD4evry9Gjx6NO3fuqFa0Xn/9dfzf//0fYmJiEBISAmtrawwbNuyu1122bBlGjBiBcePGwcfHB2PHjkV5eTkAwMXFBdOnT8eUKVPg4OCAuLg4AMDMmTMxbdo0pKSkwNfXF+Hh4di6dSs6d+4MoKYu6osvvsDmzZvh5+eH5cuXY86cORq93qeeegoTJ05EXFwc/P398fPPP2PatGl12nXt2hXDhw/HE088gcceeww9e/ZU24ZhzJgxWL16NVJTU9GjRw8MGDAAaWlpqrkSkX5JRENVoURERETUJFzBIiIiItIxBlhEREREOsYAi4iIiEjHGGARERER6RgDLCIiIiIdY4BFREREpGMMsIiIiIh0jAEWERERkY4xwCIiIiLSMQZYRERERDrGAIuIiIhIx/4f2o87E/38TS0AAAAASUVORK5CYII=",
                        "text/plain": [
                            "<Figure size 640x480 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy = 0.34285714285714286\n",
                        "Recall = 1.0\n",
                        "Precision = 0.34285714285714286\n",
                        "F1-score = 0.5106382978723404\n"
                    ]
                }
            ],
            "source": [
                "#Predict\n",
                "# x = norm_pose_train\n",
                "# y = y_train\n",
                "x = norm_pose_dev\n",
                "y = y_dev\n",
                "# x = x_dev_bad\n",
                "# y = y_dev_bad\n",
                "y_pose_prediction = model_pose.predict(x)\n",
                "y_pose_prediction = np.argmax(y_pose_prediction, axis = 1)\n",
                "\n",
                "# where_0 = np.where(y_pose_prediction == 0)\n",
                "# where_1 = np.where(y_pose_prediction == 1)\n",
                "# y_pose_prediction[where_0] = 1\n",
                "# y_pose_prediction[where_1] = 0\n",
                "\n",
                "# print(sum(y_pose_prediction)/len(y_pose_prediction))\n",
                "print(y_pose_prediction)\n",
                "#Create confusion matrix and normalizes it over predicted (columns)\n",
                "result = confusion_matrix(y, y_pose_prediction, normalize='pred')\n",
                "print(result)\n",
                "cm_display = ConfusionMatrixDisplay(confusion_matrix = result, display_labels = [\"Non-Depressed\", \"Depressed\"])\n",
                "cm_display.plot()\n",
                "plt.show()\n",
                "tn_pose = result[0][0]\n",
                "tp_pose = result[1][1]\n",
                "fn_pose = result[1][0]\n",
                "fp_pose = result[0][1]\n",
                "accuracy = (tp_pose + tn_pose)/(tp_pose + tn_pose + fp_pose + fn_pose)\n",
                "recall = tp_pose / (tp_pose + fn_pose)\n",
                "precision = tp_pose / (tp_pose + fp_pose)\n",
                "f1_score = 2 * precision * recall / (precision + recall)\n",
                "print(\"Accuracy = \" + str(accuracy))\n",
                "print(\"Recall = \" + str(recall))\n",
                "print(\"Precision = \" + str(precision))\n",
                "print(\"F1-score = \" + str(f1_score))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"model_35\"\n",
                        "__________________________________________________________________________________________________\n",
                        " Layer (type)                   Output Shape         Param #     Connected to                     \n",
                        "==================================================================================================\n",
                        " input_10 (InputLayer)          [(None, 5000, 6)]    0           []                               \n",
                        "                                                                                                  \n",
                        " conv1d_1225 (Conv1D)           (None, 5000, 128)    2432        ['input_10[0][0]']               \n",
                        "                                                                                                  \n",
                        " conv1d_1226 (Conv1D)           (None, 5000, 128)    2432        ['input_10[0][0]']               \n",
                        "                                                                                                  \n",
                        " add_700 (Add)                  (None, 5000, 128)    0           ['conv1d_1225[0][0]',            \n",
                        "                                                                  'conv1d_1226[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_525 (ELU)                  (None, 5000, 128)    0           ['add_700[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1227 (Conv1D)           (None, 5000, 128)    49280       ['elu_525[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1228 (Conv1D)           (None, 5000, 128)    49280       ['elu_525[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_701 (Add)                  (None, 5000, 128)    0           ['conv1d_1227[0][0]',            \n",
                        "                                                                  'conv1d_1228[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_526 (ELU)                  (None, 5000, 128)    0           ['add_701[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1229 (Conv1D)           (None, 5000, 128)    49280       ['elu_526[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1230 (Conv1D)           (None, 5000, 128)    49280       ['elu_526[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_702 (Add)                  (None, 5000, 128)    0           ['conv1d_1229[0][0]',            \n",
                        "                                                                  'conv1d_1230[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_527 (ELU)                  (None, 5000, 128)    0           ['add_702[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1231 (Conv1D)           (None, 5000, 128)    896         ['input_10[0][0]']               \n",
                        "                                                                                                  \n",
                        " add_703 (Add)                  (None, 5000, 128)    0           ['elu_527[0][0]',                \n",
                        "                                                                  'conv1d_1231[0][0]']            \n",
                        "                                                                                                  \n",
                        " batch_normalization_20 (BatchN  (None, 5000, 128)   512         ['add_703[0][0]']                \n",
                        " ormalization)                                                                                    \n",
                        "                                                                                                  \n",
                        " max_pooling1d_140 (MaxPooling1  (None, 2500, 128)   0           ['batch_normalization_20[0][0]'] \n",
                        " D)                                                                                               \n",
                        "                                                                                                  \n",
                        " conv1d_1232 (Conv1D)           (None, 2500, 64)     24640       ['max_pooling1d_140[0][0]']      \n",
                        "                                                                                                  \n",
                        " conv1d_1233 (Conv1D)           (None, 2500, 64)     24640       ['max_pooling1d_140[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_704 (Add)                  (None, 2500, 64)     0           ['conv1d_1232[0][0]',            \n",
                        "                                                                  'conv1d_1233[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_528 (ELU)                  (None, 2500, 64)     0           ['add_704[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1234 (Conv1D)           (None, 2500, 64)     12352       ['elu_528[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1235 (Conv1D)           (None, 2500, 64)     12352       ['elu_528[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_705 (Add)                  (None, 2500, 64)     0           ['conv1d_1234[0][0]',            \n",
                        "                                                                  'conv1d_1235[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_529 (ELU)                  (None, 2500, 64)     0           ['add_705[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1236 (Conv1D)           (None, 2500, 64)     12352       ['elu_529[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1237 (Conv1D)           (None, 2500, 64)     12352       ['elu_529[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_706 (Add)                  (None, 2500, 64)     0           ['conv1d_1236[0][0]',            \n",
                        "                                                                  'conv1d_1237[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_530 (ELU)                  (None, 2500, 64)     0           ['add_706[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1238 (Conv1D)           (None, 2500, 64)     8256        ['max_pooling1d_140[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_707 (Add)                  (None, 2500, 64)     0           ['elu_530[0][0]',                \n",
                        "                                                                  'conv1d_1238[0][0]']            \n",
                        "                                                                                                  \n",
                        " batch_normalization_21 (BatchN  (None, 2500, 64)    256         ['add_707[0][0]']                \n",
                        " ormalization)                                                                                    \n",
                        "                                                                                                  \n",
                        " max_pooling1d_141 (MaxPooling1  (None, 1250, 64)    0           ['batch_normalization_21[0][0]'] \n",
                        " D)                                                                                               \n",
                        "                                                                                                  \n",
                        " conv1d_1239 (Conv1D)           (None, 1250, 256)    49408       ['max_pooling1d_141[0][0]']      \n",
                        "                                                                                                  \n",
                        " conv1d_1240 (Conv1D)           (None, 1250, 256)    49408       ['max_pooling1d_141[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_708 (Add)                  (None, 1250, 256)    0           ['conv1d_1239[0][0]',            \n",
                        "                                                                  'conv1d_1240[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_531 (ELU)                  (None, 1250, 256)    0           ['add_708[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1241 (Conv1D)           (None, 1250, 256)    196864      ['elu_531[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1242 (Conv1D)           (None, 1250, 256)    196864      ['elu_531[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_709 (Add)                  (None, 1250, 256)    0           ['conv1d_1241[0][0]',            \n",
                        "                                                                  'conv1d_1242[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_532 (ELU)                  (None, 1250, 256)    0           ['add_709[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1243 (Conv1D)           (None, 1250, 256)    196864      ['elu_532[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1244 (Conv1D)           (None, 1250, 256)    196864      ['elu_532[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_710 (Add)                  (None, 1250, 256)    0           ['conv1d_1243[0][0]',            \n",
                        "                                                                  'conv1d_1244[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_533 (ELU)                  (None, 1250, 256)    0           ['add_710[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1245 (Conv1D)           (None, 1250, 256)    16640       ['max_pooling1d_141[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_711 (Add)                  (None, 1250, 256)    0           ['elu_533[0][0]',                \n",
                        "                                                                  'conv1d_1245[0][0]']            \n",
                        "                                                                                                  \n",
                        " batch_normalization_22 (BatchN  (None, 1250, 256)   1024        ['add_711[0][0]']                \n",
                        " ormalization)                                                                                    \n",
                        "                                                                                                  \n",
                        " max_pooling1d_142 (MaxPooling1  (None, 625, 256)    0           ['batch_normalization_22[0][0]'] \n",
                        " D)                                                                                               \n",
                        "                                                                                                  \n",
                        " conv1d_1246 (Conv1D)           (None, 625, 128)     98432       ['max_pooling1d_142[0][0]']      \n",
                        "                                                                                                  \n",
                        " conv1d_1247 (Conv1D)           (None, 625, 128)     98432       ['max_pooling1d_142[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_712 (Add)                  (None, 625, 128)     0           ['conv1d_1246[0][0]',            \n",
                        "                                                                  'conv1d_1247[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_534 (ELU)                  (None, 625, 128)     0           ['add_712[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1248 (Conv1D)           (None, 625, 128)     49280       ['elu_534[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1249 (Conv1D)           (None, 625, 128)     49280       ['elu_534[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_713 (Add)                  (None, 625, 128)     0           ['conv1d_1248[0][0]',            \n",
                        "                                                                  'conv1d_1249[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_535 (ELU)                  (None, 625, 128)     0           ['add_713[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1250 (Conv1D)           (None, 625, 128)     49280       ['elu_535[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1251 (Conv1D)           (None, 625, 128)     49280       ['elu_535[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_714 (Add)                  (None, 625, 128)     0           ['conv1d_1250[0][0]',            \n",
                        "                                                                  'conv1d_1251[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_536 (ELU)                  (None, 625, 128)     0           ['add_714[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1252 (Conv1D)           (None, 625, 128)     32896       ['max_pooling1d_142[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_715 (Add)                  (None, 625, 128)     0           ['elu_536[0][0]',                \n",
                        "                                                                  'conv1d_1252[0][0]']            \n",
                        "                                                                                                  \n",
                        " batch_normalization_23 (BatchN  (None, 625, 128)    512         ['add_715[0][0]']                \n",
                        " ormalization)                                                                                    \n",
                        "                                                                                                  \n",
                        " max_pooling1d_143 (MaxPooling1  (None, 312, 128)    0           ['batch_normalization_23[0][0]'] \n",
                        " D)                                                                                               \n",
                        "                                                                                                  \n",
                        " conv1d_1253 (Conv1D)           (None, 312, 64)      24640       ['max_pooling1d_143[0][0]']      \n",
                        "                                                                                                  \n",
                        " conv1d_1254 (Conv1D)           (None, 312, 64)      24640       ['max_pooling1d_143[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_716 (Add)                  (None, 312, 64)      0           ['conv1d_1253[0][0]',            \n",
                        "                                                                  'conv1d_1254[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_537 (ELU)                  (None, 312, 64)      0           ['add_716[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1255 (Conv1D)           (None, 312, 64)      12352       ['elu_537[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1256 (Conv1D)           (None, 312, 64)      12352       ['elu_537[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_717 (Add)                  (None, 312, 64)      0           ['conv1d_1255[0][0]',            \n",
                        "                                                                  'conv1d_1256[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_538 (ELU)                  (None, 312, 64)      0           ['add_717[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1257 (Conv1D)           (None, 312, 64)      12352       ['elu_538[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1258 (Conv1D)           (None, 312, 64)      12352       ['elu_538[0][0]']                \n",
                        "                                                                                                  \n",
                        " add_718 (Add)                  (None, 312, 64)      0           ['conv1d_1257[0][0]',            \n",
                        "                                                                  'conv1d_1258[0][0]']            \n",
                        "                                                                                                  \n",
                        " elu_539 (ELU)                  (None, 312, 64)      0           ['add_718[0][0]']                \n",
                        "                                                                                                  \n",
                        " conv1d_1259 (Conv1D)           (None, 312, 64)      8256        ['max_pooling1d_143[0][0]']      \n",
                        "                                                                                                  \n",
                        " add_719 (Add)                  (None, 312, 64)      0           ['elu_539[0][0]',                \n",
                        "                                                                  'conv1d_1259[0][0]']            \n",
                        "                                                                                                  \n",
                        " global_average_pooling1d_35 (G  (None, 64)          0           ['add_719[0][0]']                \n",
                        " lobalAveragePooling1D)                                                                           \n",
                        "                                                                                                  \n",
                        " dense_210 (Dense)              (None, 64)           4160        ['global_average_pooling1d_35[0][\n",
                        "                                                                 0]']                             \n",
                        "                                                                                                  \n",
                        " tf.nn.relu_35 (TFOpLambda)     (None, 64)           0           ['dense_210[0][0]']              \n",
                        "                                                                                                  \n",
                        " dense_211 (Dense)              (None, 64)           4160        ['tf.nn.relu_35[0][0]']          \n",
                        "                                                                                                  \n",
                        " tf.math.sigmoid_35 (TFOpLambda  (None, 64)          0           ['dense_211[0][0]']              \n",
                        " )                                                                                                \n",
                        "                                                                                                  \n",
                        " multiply_35 (Multiply)         (None, 312, 64)      0           ['add_719[0][0]',                \n",
                        "                                                                  'tf.math.sigmoid_35[0][0]']     \n",
                        "                                                                                                  \n",
                        " flatten_35 (Flatten)           (None, 19968)        0           ['multiply_35[0][0]']            \n",
                        "                                                                                                  \n",
                        " dense_212 (Dense)              (None, 15000)        299535000   ['flatten_35[0][0]']             \n",
                        "                                                                                                  \n",
                        " dense_213 (Dense)              (None, 9000)         135009000   ['dense_212[0][0]']              \n",
                        "                                                                                                  \n",
                        " dense_214 (Dense)              (None, 2)            18002       ['dense_213[0][0]']              \n",
                        "                                                                                                  \n",
                        " softmax_35 (Softmax)           (None, 2)            0           ['dense_214[0][0]']              \n",
                        "                                                                                                  \n",
                        "==================================================================================================\n",
                        "Total params: 436,319,186\n",
                        "Trainable params: 436,318,034\n",
                        "Non-trainable params: 1,152\n",
                        "__________________________________________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "# model_pose.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
                    ]
                }
            ],
            "source": [
                "plot_model(model_pose, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model_pose.save(\"saved_models/pose_madeupdata_20_7\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "attempt2",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
